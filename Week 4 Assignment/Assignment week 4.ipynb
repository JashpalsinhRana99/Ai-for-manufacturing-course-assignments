{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0074b982-016d-4360-a00b-1ac12375564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, asin, sqrt\n",
    "# This line imports specific functions from the math library that are used for calculating the haversine distance between two points on a globe.\n",
    "\n",
    "import pandas as pd\n",
    "# This line imports the Pandas library, which is a popular library for data manipulation and analysis.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# This line imports the LabelEncoder and StandardScaler classes from the scikit-learn library, which are used for preprocessing data for machine learning models.\n",
    "\n",
    "import time\n",
    "# This line imports the time module, which is used for timing the execution of code\n",
    "\n",
    "import numpy as np\n",
    "# This line imports the NumPy library, which provides support for numerical computing with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a5ca0c-582e-4be2-8cc0-d4ca4654ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv(\"./data/olist_orders_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_orders_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"orders\".\n",
    "\n",
    "items = pd.read_csv(\"./data/olist_order_items_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_order_items_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"items\".\n",
    "\n",
    "customers = pd.read_csv(\"./data/olist_customers_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_customers_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"customers\".\n",
    "\n",
    "sellers = pd.read_csv(\"./data/olist_sellers_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_sellers_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"sellers\".\n",
    "\n",
    "geo = pd.read_csv(\"./data/olist_geolocation_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_geolocation_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"geo\".\n",
    "\n",
    "products = pd.read_csv(\"./data/olist_products_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_products_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"products\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c603063-0a1c-48ad-afa8-cf00ba8863f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf84af5-0fe8-43e4-9219-584282116b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cef67bcfe19066a932b7673e239eb23d</td>\n",
       "      <td>bebes</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9dc1a7de274444849c219cff195d0b71</td>\n",
       "      <td>utilidades_domesticas</td>\n",
       "      <td>37.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
       "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
       "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "0                 40.0                       287.0                 1.0   \n",
       "1                 44.0                       276.0                 1.0   \n",
       "2                 46.0                       250.0                 1.0   \n",
       "3                 27.0                       261.0                 1.0   \n",
       "4                 37.0                       402.0                 4.0   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
       "0             225.0               16.0               10.0              14.0  \n",
       "1            1000.0               30.0               18.0              20.0  \n",
       "2             154.0               18.0                9.0              15.0  \n",
       "3             371.0               26.0                4.0              26.0  \n",
       "4             625.0               20.0               17.0              13.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b733fc6-ae50-41e4-acb6-feb7087bdcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f8fa7d-b83c-47e9-bb3e-8b2f19672839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d401f27-2994-4ed6-8e49-358d30e7b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "products.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "348ad6b2-12e5-4239-a161-a1127a488348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23b41f8e-99f0-44f9-bd7a-b65efe82aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sellers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "815395ec-365b-45df-927d-e775f5e3c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93522852-e959-4a29-b580-1035cdf8cdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date                         seller_id  \\\n",
       "0           2017-10-18 00:00:00  3504c0cb71d7fa48d967e0e4c94d59d9   \n",
       "1           2018-08-13 00:00:00  289cdb325fb7e7f891c38608bf9e0962   \n",
       "2           2018-09-04 00:00:00  4869f7a5dfa277a7dca6462dcf3b52b2   \n",
       "3           2017-12-15 00:00:00  66922902710d126a0e7d26b0e3805106   \n",
       "4           2018-02-26 00:00:00  2c9e548be18521d1c43cde1c582c6de8   \n",
       "\n",
       "   seller_zip_code_prefix  \n",
       "0                  9350.0  \n",
       "1                 31570.0  \n",
       "2                 14840.0  \n",
       "3                 31842.0  \n",
       "4                  8752.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the seller zip code of each order\n",
    "\n",
    "middle = items[['order_id', 'seller_id']]\n",
    "# This line creates a new dataframe middle that contains only the order_id and seller_id columns from the items dataframe.\n",
    "\n",
    "middle_2 = middle.merge(sellers[['seller_id', 'seller_zip_code_prefix']], on=\"seller_id\", how=\"outer\")\n",
    "# This line merges the middle dataframe with the seller_id and seller_zip_code_prefix columns from the sellers dataframe, creating a new dataframe middle_2. The outer join type is used, which means that all rows from both dataframes are included in the merged dataframe, and missing values are filled with NaN.\n",
    "\n",
    "orders = orders.merge(middle_2, on=\"order_id\", how=\"left\")\n",
    "# This line merges the orders dataframe with the middle_2 dataframe on the order_id column, creating a new orders dataframe. The left join type is used, which means that all rows from the orders dataframe are included in the merged dataframe, and missing values from the middle_2 dataframe are filled with NaN.\n",
    "\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37eaaef0-0575-416d-b0fd-90f730c60620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>3149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>47813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>75265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>59296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>9195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date                         seller_id  \\\n",
       "0           2017-10-18 00:00:00  3504c0cb71d7fa48d967e0e4c94d59d9   \n",
       "1           2018-08-13 00:00:00  289cdb325fb7e7f891c38608bf9e0962   \n",
       "2           2018-09-04 00:00:00  4869f7a5dfa277a7dca6462dcf3b52b2   \n",
       "3           2017-12-15 00:00:00  66922902710d126a0e7d26b0e3805106   \n",
       "4           2018-02-26 00:00:00  2c9e548be18521d1c43cde1c582c6de8   \n",
       "\n",
       "   seller_zip_code_prefix  customer_zip_code_prefix  \n",
       "0                  9350.0                      3149  \n",
       "1                 31570.0                     47813  \n",
       "2                 14840.0                     75265  \n",
       "3                 31842.0                     59296  \n",
       "4                  8752.0                      9195  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get customer zip code of each order\n",
    "orders = orders.merge(customers[['customer_id', 'customer_zip_code_prefix']],\n",
    "                  on='customer_id', how=\"left\")\n",
    "# The code above performs a left merge operation between two Pandas dataframes named \"orders\" and \"customers\" using the \"customer_id\" column as the joining key. It then selects the \"customer_id\" and \"customer_zip_code_prefix\" columns from the \"customers\" dataframe and merges them with the \"orders\" dataframe based on the matching \"customer_id\" column.\n",
    "\n",
    "\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e550201-2b69-4fea-8de0-336b85af6ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>-23.545621</td>\n",
       "      <td>-46.639292</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546081</td>\n",
       "      <td>-46.644820</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041</td>\n",
       "      <td>-23.544392</td>\n",
       "      <td>-46.639499</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>-23.541578</td>\n",
       "      <td>-46.641607</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1012</td>\n",
       "      <td>-23.547762</td>\n",
       "      <td>-46.635361</td>\n",
       "      <td>são paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                         1037       -23.545621       -46.639292   \n",
       "1                         1046       -23.546081       -46.644820   \n",
       "3                         1041       -23.544392       -46.639499   \n",
       "4                         1035       -23.541578       -46.641607   \n",
       "5                         1012       -23.547762       -46.635361   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0        sao paulo                SP  \n",
       "1        sao paulo                SP  \n",
       "3        sao paulo                SP  \n",
       "4        sao paulo                SP  \n",
       "5        são paulo                SP  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean geo df\n",
    "geo = geo[~geo['geolocation_zip_code_prefix'].duplicated()]\n",
    "'''\n",
    "This line first selects the 'geolocation_zip_code_prefix' column from the 'geo' DataFrame using the indexing operator []. The duplicated() method is then called on this column to create a boolean mask of rows that have duplicate values in this column.\n",
    "\n",
    "The tilde operator (~) is used to invert this boolean mask, so that the mask contains True for rows that do not have duplicate values in this column.\n",
    "'''\n",
    "\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b35ee581-16a5-4e58-9c58-e010c220f431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>3149</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>-23.680114</td>\n",
       "      <td>-46.452454</td>\n",
       "      <td>maua</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>47813</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>-19.810119</td>\n",
       "      <td>-43.984727</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>75265</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>-21.362358</td>\n",
       "      <td>-48.232976</td>\n",
       "      <td>guariba</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>59296</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>-19.840168</td>\n",
       "      <td>-43.923299</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>9195</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>-23.551707</td>\n",
       "      <td>-46.260979</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date                         seller_id  \\\n",
       "0           2017-10-18 00:00:00  3504c0cb71d7fa48d967e0e4c94d59d9   \n",
       "1           2018-08-13 00:00:00  289cdb325fb7e7f891c38608bf9e0962   \n",
       "2           2018-09-04 00:00:00  4869f7a5dfa277a7dca6462dcf3b52b2   \n",
       "3           2017-12-15 00:00:00  66922902710d126a0e7d26b0e3805106   \n",
       "4           2018-02-26 00:00:00  2c9e548be18521d1c43cde1c582c6de8   \n",
       "\n",
       "   seller_zip_code_prefix  customer_zip_code_prefix  \\\n",
       "0                  9350.0                      3149   \n",
       "1                 31570.0                     47813   \n",
       "2                 14840.0                     75265   \n",
       "3                 31842.0                     59296   \n",
       "4                  8752.0                      9195   \n",
       "\n",
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                       9350.0       -23.680114       -46.452454   \n",
       "1                      31570.0       -19.810119       -43.984727   \n",
       "2                      14840.0       -21.362358       -48.232976   \n",
       "3                      31842.0       -19.840168       -43.923299   \n",
       "4                       8752.0       -23.551707       -46.260979   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0             maua                SP  \n",
       "1   belo horizonte                MG  \n",
       "2          guariba                SP  \n",
       "3   belo horizonte                MG  \n",
       "4  mogi das cruzes                SP  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add seller coordinates to the orders\n",
    "orders = orders.merge(geo, left_on=\"seller_zip_code_prefix\",\n",
    "                      right_on=\"geolocation_zip_code_prefix\", how=\"left\")\n",
    "'''\n",
    "The code above performs a left join of two dataframes - \"orders\" and \"geo\" - using the \"seller_zip_code_prefix\" column of the \"orders\" dataframe and the \"geolocation_zip_code_prefix\" column of the \"geo\" dataframe as the join keys.\n",
    "'''\n",
    "                      \n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "734b64c0-3472-4320-a084-60b4cc65cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add customer coordinates to the orders\n",
    "orders = orders.merge(geo, left_on=\"customer_zip_code_prefix\",\n",
    "                      right_on=\"geolocation_zip_code_prefix\", how=\"left\",\n",
    "                      suffixes=(\"_seller\", \"_customer\"))\n",
    "# This code merges two Pandas DataFrames, orders and geo, on a common column, customer_zip_code_prefix in orders and geolocation_zip_code_prefix in geo. The resulting merged DataFrame contains all the columns from both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ccd6eb4-3aa6-4139-8838-59281db1d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean orders\n",
    "# 1-Filter out orders with multiple sellers Because each order only has one delivery date\n",
    "df = orders.groupby(by=\"order_id\").nunique()\n",
    "# Groups the orders by order_id and calculates the number of unique values in each group using the nunique() method.\n",
    "\n",
    "mono_orders = pd.Series(df[df['seller_id'] == 1].index)\n",
    "# Selects the indices of the resulting DataFrame where the seller_id column equals 1 and stores them in a Pandas Series called mono_orders.\n",
    "\n",
    "filtered_orders = orders.merge(mono_orders, how='inner')\n",
    "# Merges the original orders DataFrame with mono_orders based on the order_id column using an inner join and stores the resulting DataFrame in a variable called filtered_orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efb28960-22f8-4ff5-af2b-f56c129fde80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>...</th>\n",
       "      <th>geolocation_zip_code_prefix_y</th>\n",
       "      <th>geolocation_lat_y</th>\n",
       "      <th>geolocation_lng_y</th>\n",
       "      <th>geolocation_city_y</th>\n",
       "      <th>geolocation_state_y</th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>-23.680114</td>\n",
       "      <td>-46.452454</td>\n",
       "      <td>maua</td>\n",
       "      <td>SP</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>-23.574809</td>\n",
       "      <td>-46.587471</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>47813</td>\n",
       "      <td>...</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>-19.810119</td>\n",
       "      <td>-43.984727</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>47813.0</td>\n",
       "      <td>-12.169860</td>\n",
       "      <td>-44.988369</td>\n",
       "      <td>barreiras</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>75265</td>\n",
       "      <td>...</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>-21.362358</td>\n",
       "      <td>-48.232976</td>\n",
       "      <td>guariba</td>\n",
       "      <td>SP</td>\n",
       "      <td>75265.0</td>\n",
       "      <td>-16.746337</td>\n",
       "      <td>-48.514624</td>\n",
       "      <td>vianopolis</td>\n",
       "      <td>GO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>59296</td>\n",
       "      <td>...</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>-19.840168</td>\n",
       "      <td>-43.923299</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>59296.0</td>\n",
       "      <td>-5.767733</td>\n",
       "      <td>-35.275467</td>\n",
       "      <td>sao goncalo do amarante</td>\n",
       "      <td>RN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>9195</td>\n",
       "      <td>...</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>-23.551707</td>\n",
       "      <td>-46.260979</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "      <td>9195.0</td>\n",
       "      <td>-23.675037</td>\n",
       "      <td>-46.524784</td>\n",
       "      <td>santo andre</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp order_delivered_carrier_date  \\\n",
       "0    delivered      2017-10-02 10:56:33          2017-10-04 19:55:00   \n",
       "1    delivered      2018-07-24 20:41:37          2018-07-26 14:31:00   \n",
       "2    delivered      2018-08-08 08:38:49          2018-08-08 13:50:00   \n",
       "3    delivered      2017-11-18 19:28:06          2017-11-22 13:39:59   \n",
       "4    delivered      2018-02-13 21:18:39          2018-02-14 19:46:34   \n",
       "\n",
       "  order_delivered_customer_date order_estimated_delivery_date  \\\n",
       "0           2017-10-10 21:25:13           2017-10-18 00:00:00   \n",
       "1           2018-08-07 15:27:45           2018-08-13 00:00:00   \n",
       "2           2018-08-17 18:06:29           2018-09-04 00:00:00   \n",
       "3           2017-12-02 00:28:42           2017-12-15 00:00:00   \n",
       "4           2018-02-16 18:17:02           2018-02-26 00:00:00   \n",
       "\n",
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3504c0cb71d7fa48d967e0e4c94d59d9                  9350.0   \n",
       "1  289cdb325fb7e7f891c38608bf9e0962                 31570.0   \n",
       "2  4869f7a5dfa277a7dca6462dcf3b52b2                 14840.0   \n",
       "3  66922902710d126a0e7d26b0e3805106                 31842.0   \n",
       "4  2c9e548be18521d1c43cde1c582c6de8                  8752.0   \n",
       "\n",
       "   customer_zip_code_prefix  ...  geolocation_zip_code_prefix_y  \\\n",
       "0                      3149  ...                         9350.0   \n",
       "1                     47813  ...                        31570.0   \n",
       "2                     75265  ...                        14840.0   \n",
       "3                     59296  ...                        31842.0   \n",
       "4                      9195  ...                         8752.0   \n",
       "\n",
       "   geolocation_lat_y  geolocation_lng_y geolocation_city_y  \\\n",
       "0         -23.680114         -46.452454               maua   \n",
       "1         -19.810119         -43.984727     belo horizonte   \n",
       "2         -21.362358         -48.232976            guariba   \n",
       "3         -19.840168         -43.923299     belo horizonte   \n",
       "4         -23.551707         -46.260979    mogi das cruzes   \n",
       "\n",
       "  geolocation_state_y  geolocation_zip_code_prefix  geolocation_lat  \\\n",
       "0                  SP                       3149.0       -23.574809   \n",
       "1                  MG                      47813.0       -12.169860   \n",
       "2                  SP                      75265.0       -16.746337   \n",
       "3                  MG                      59296.0        -5.767733   \n",
       "4                  SP                       9195.0       -23.675037   \n",
       "\n",
       "   geolocation_lng         geolocation_city geolocation_state  \n",
       "0       -46.587471                sao paulo                SP  \n",
       "1       -44.988369                barreiras                BA  \n",
       "2       -48.514624               vianopolis                GO  \n",
       "3       -35.275467  sao goncalo do amarante                RN  \n",
       "4       -46.524784              santo andre                SP  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-drop rows with missing values\n",
    "filtered_orders = filtered_orders.drop(columns=[\"order_approved_at\"])\n",
    "# This line drops the \"order_approved_at\" column from the filtered_orders DataFrame. This column is not necessary for the analysis being performed.\n",
    "\n",
    "filtered_orders = filtered_orders.dropna()\n",
    "# This line drops any rows in the filtered_orders DataFrame that contain missing values. This is a common data preprocessing step to ensure that the dataset is clean and complete.\n",
    "\n",
    "\n",
    "filtered_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d922f2c8-8b00-4102-94ca-f4fc070415f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function to calculate distance\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Compute distance between two pairs of (lat, lng)\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * 6371 * asin(sqrt(a))\n",
    "\n",
    "# This line defines a function called haversine_distance that takes four arguments: lon1, lat1, lon2, and lat2. These arguments represent the longitude and latitude coordinates of two points on the globe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59aa4df3-7751-47fc-8da6-0855b86268ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_package_size(items, products):\n",
    "    # Get Package Size\n",
    "    df_tmp = items[['order_id', 'product_id']].merge(products[['product_id', 'product_length_cm', 'product_height_cm',\n",
    "                                                               'product_width_cm', 'product_weight_g']],\n",
    "                                                     on=\"product_id\",\n",
    "                                                     how=\"outer\")\n",
    "    df_tmp.loc[:, \"product_size_cm3\"] = \\\n",
    "        df_tmp['product_length_cm']*df_tmp['product_width_cm'] * df_tmp['product_height_cm']\n",
    "    orders_size_weight = df_tmp.groupby(\"order_id\", as_index=False).sum()[['order_id', 'product_size_cm3',\n",
    "                                                                           'product_weight_g']]\n",
    "    return orders_size_weight\n",
    "\n",
    "# The code above defines a function called get_package_size that takes two arguments: items and products, which are Pandas DataFrames containing information about products and the items ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a009211d-fd05-4bda-8f43-c38c467e66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_int(dataframe_series):\n",
    "\n",
    "    if dataframe_series.dtype == 'object':\n",
    "        # This line checks if the data type of the input dataframe_series is \"object\", which typically represents string or categorical data.\n",
    "\n",
    "        dataframe_series = LabelEncoder().fit_transform(dataframe_series)\n",
    "        # This line uses the LabelEncoder() method from the scikit-learn library to encode the string or categorical data as integers. This is a common preprocessing step in machine learning to convert non-numeric data into a format that can be used by algorithms. The fit_transform() method fits the encoder to the data and transforms it.\n",
    "        \n",
    "    return dataframe_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f0bdd94-ce92-4699-80e8-77bf64427f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe code above applies the describe() method to a Pandas DataFrame called orders, which provides summary statistics of the data in the DataFrame. Here's a brief explanation of what each statistic means:\\n\\ncount: the number of non-missing values in each column\\nmean: the average value of each column\\nstd: the standard deviation of each column\\nmin: the minimum value of each column\\n25%: the first quartile of each column (25th percentile)\\n50%: the second quartile of each column (50th percentile, equivalent to the median)\\n75%: the third quartile of each column (75th percentile)\\nmax: the maximum value of each column\\nThe describe() method is useful for quickly getting an overview of the data in a DataFrame, including identifying potential outliers or unusual patterns in the data.\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It gives the numerical statistical information of the dataframe\n",
    "orders.describe()\n",
    "\n",
    "'''\n",
    "The code above applies the describe() method to a Pandas DataFrame called orders, which provides summary statistics of the data in the DataFrame. Here's a brief explanation of what each statistic means:\n",
    "\n",
    "count: the number of non-missing values in each column\n",
    "mean: the average value of each column\n",
    "std: the standard deviation of each column\n",
    "min: the minimum value of each column\n",
    "25%: the first quartile of each column (25th percentile)\n",
    "50%: the second quartile of each column (50th percentile, equivalent to the median)\n",
    "75%: the third quartile of each column (75th percentile)\n",
    "max: the maximum value of each column\n",
    "The describe() method is useful for quickly getting an overview of the data in a DataFrame, including identifying potential outliers or unusual patterns in the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f6ed52-4e6b-4a46-b771-673115ad1320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                            0\n",
       "customer_id                         0\n",
       "order_status                        0\n",
       "order_purchase_timestamp            0\n",
       "order_approved_at                 161\n",
       "order_delivered_carrier_date     1968\n",
       "order_delivered_customer_date    3229\n",
       "order_estimated_delivery_date       0\n",
       "seller_id                         775\n",
       "seller_zip_code_prefix            775\n",
       "customer_zip_code_prefix            0\n",
       "geolocation_zip_code_prefix_x    1028\n",
       "geolocation_lat_x                1028\n",
       "geolocation_lng_x                1028\n",
       "geolocation_city_x               1028\n",
       "geolocation_state_x              1028\n",
       "geolocation_zip_code_prefix_y    1028\n",
       "geolocation_lat_y                1028\n",
       "geolocation_lng_y                1028\n",
       "geolocation_city_y               1028\n",
       "geolocation_state_y              1028\n",
       "geolocation_zip_code_prefix       306\n",
       "geolocation_lat                   306\n",
       "geolocation_lng                   306\n",
       "geolocation_city                  306\n",
       "geolocation_state                 306\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It returns the number of null values in the dataframe for every column feature\n",
    "# Using info() we can view the number of non-null values whereas isnull() gives the number of null values\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfb395e0-e8bd-489c-87df-c7015727b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X_train, X_test):\n",
    "    '''\n",
    "    The code above defines a function called scaling that performs feature scaling using the StandardScaler class from scikit-learn.\n",
    "    '''\n",
    "    sc_X = StandardScaler()\n",
    "    X_train_scaled = sc_X.fit_transform(X_train)\n",
    "    X_test_scaled = sc_X.fit_transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d477332-5684-4031-867e-cee796d407c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(final_df, columns_for_train, columns_for_pred, i_flag):\n",
    "    '''\n",
    "    This function is a convenient way to split a DataFrame into training and testing sets for machine learning purposes. The i_flag parameter is used to avoid a warning message related to the NumPy library, and the columns_for_train and columns_for_pred parameters allow for flexible selection of features and target variables.\n",
    "    '''\n",
    "\n",
    "    if i_flag:\n",
    "        from sklearnex import patch_sklearn  # pylint: disable=C0415, E0401\n",
    "        patch_sklearn()\n",
    "    from sklearn.model_selection import train_test_split  # pylint: disable=C0415\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(final_df[columns_for_train], final_df[columns_for_pred],\n",
    "                                                        test_size=0.3, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1fccc2a-cebc-492c-b852-04b5a72230b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial State Check ---\n",
      "Columns: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date', 'seller_id', 'seller_zip_code_prefix', 'customer_zip_code_prefix', 'geolocation_zip_code_prefix_x', 'geolocation_lat_x', 'geolocation_lng_x', 'geolocation_city_x', 'geolocation_state_x', 'geolocation_zip_code_prefix_y', 'geolocation_lat_y', 'geolocation_lng_y', 'geolocation_city_y', 'geolocation_state_y', 'geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng', 'geolocation_city', 'geolocation_state', 'distance', 'product_size_cm3_x', 'product_weight_g_x', 'product_size_cm3_y', 'product_weight_g_y', 'wait_time', 'est_wait_time', 'purchase_dow', 'year', 'purchase_month']\n",
      "Shape: (106578, 35)\n",
      "\n",
      "--- Step 1: Dropping stale calculation columns ---\n",
      "Dropped: ['wait_time', 'est_wait_time', 'purchase_dow', 'year', 'purchase_month', 'distance']\n",
      "\n",
      "--- Step 2: Resolving product column suffixes ---\n",
      "Renamed product columns: {'product_size_cm3_x': 'product_size_cm3', 'product_weight_g_x': 'product_weight_g'}\n",
      "Dropped unused product columns: ['product_size_cm3_y', 'product_weight_g_y']\n",
      "\n",
      "--- Step 3: Renaming geolocation state columns ---\n",
      "Renamed geolocation state columns: {'geolocation_state_x': 'geolocation_state_seller', 'geolocation_state_y': 'geolocation_state_customer'}\n",
      "\n",
      "--- Starting Main Processing Block ---\n",
      "Calculating Haversine distance...\n",
      "Distance calculation complete.\n",
      "Converting time columns...\n",
      "Time column conversion complete.\n",
      "Calculating wait times...\n",
      "Warning: Cannot calculate actual wait time.\n",
      "Warning: Cannot calculate estimated wait time.\n",
      "Extracting date components...\n",
      "Warning: Cannot extract date components.\n",
      "Creating final DataFrame...\n",
      "Calculating delay feature...\n",
      "Encoding object columns...\n",
      "\n",
      "First 5 rows of the final encoded DataFrame (final_df_enc):\n",
      "   purchase_dow  purchase_month  year  product_size_cm3  product_weight_g  \\\n",
      "0           NaN             NaN   NaN            1976.0             500.0   \n",
      "1           NaN             NaN   NaN            4693.0             400.0   \n",
      "2           NaN             NaN   NaN            9576.0             420.0   \n",
      "3           NaN             NaN   NaN            6000.0             450.0   \n",
      "4           NaN             NaN   NaN           11475.0             250.0   \n",
      "\n",
      "   geolocation_state_customer  geolocation_state_seller  distance  wait_time  \\\n",
      "0                          20                        20       0.0        NaN   \n",
      "1                           7                         7       0.0        NaN   \n",
      "2                          20                        20       0.0        NaN   \n",
      "3                           7                         7       0.0        NaN   \n",
      "4                          20                        20       0.0        NaN   \n",
      "\n",
      "   est_wait_time  delay  \n",
      "0            NaN      0  \n",
      "1            NaN      0  \n",
      "2            NaN      0  \n",
      "3            NaN      0  \n",
      "4            NaN      0  \n",
      "\n",
      "Final DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106578 entries, 0 to 106577\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   purchase_dow                0 non-null       float64\n",
      " 1   purchase_month              0 non-null       float64\n",
      " 2   year                        0 non-null       float64\n",
      " 3   product_size_cm3            106578 non-null  float64\n",
      " 4   product_weight_g            106578 non-null  float64\n",
      " 5   geolocation_state_customer  106578 non-null  int32  \n",
      " 6   geolocation_state_seller    106578 non-null  int32  \n",
      " 7   distance                    106578 non-null  float64\n",
      " 8   wait_time                   0 non-null       float64\n",
      " 9   est_wait_time               0 non-null       float64\n",
      " 10  delay                       106578 non-null  int32  \n",
      "dtypes: float64(8), int32(3)\n",
      "memory usage: 7.7 MB\n",
      "None\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "# Assuming haversine_distance, get_package_size, object_to_int are defined elsewhere\n",
    "# Assuming filtered_orders is in the state shown by your .info() output\n",
    "\n",
    "print(\"--- Initial State Check ---\")\n",
    "print(f\"Columns: {filtered_orders.columns.tolist()}\")\n",
    "print(f\"Shape: {filtered_orders.shape}\")\n",
    "\n",
    "# --- Step 1: Clean up stale/incorrect columns from previous failed attempts ---\n",
    "print(\"\\n--- Step 1: Dropping stale calculation columns ---\")\n",
    "cols_to_drop = ['wait_time', 'est_wait_time', 'purchase_dow', 'year', 'purchase_month', 'distance']\n",
    "# Check which ones actually exist before dropping\n",
    "cols_exist_to_drop = [col for col in cols_to_drop if col in filtered_orders.columns]\n",
    "if cols_exist_to_drop:\n",
    "    filtered_orders = filtered_orders.drop(columns=cols_exist_to_drop)\n",
    "    print(f\"Dropped: {cols_exist_to_drop}\")\n",
    "else:\n",
    "    print(\"No stale calculation columns found to drop.\")\n",
    "\n",
    "# --- Step 2: Resolve Product Column Suffixes ---\n",
    "print(\"\\n--- Step 2: Resolving product column suffixes ---\")\n",
    "# IMPORTANT: Assuming the '_x' columns are the correct ones you want to keep.\n",
    "# Verify this assumption based on your data preparation steps!\n",
    "product_rename_map = {\n",
    "    'product_size_cm3_x': 'product_size_cm3',\n",
    "    'product_weight_g_x': 'product_weight_g'\n",
    "}\n",
    "product_cols_to_drop = ['product_size_cm3_y', 'product_weight_g_y']\n",
    "\n",
    "# Check if _x columns exist for renaming\n",
    "product_cols_to_rename = {k: v for k, v in product_rename_map.items() if k in filtered_orders.columns}\n",
    "if product_cols_to_rename:\n",
    "    filtered_orders = filtered_orders.rename(columns=product_cols_to_rename)\n",
    "    print(f\"Renamed product columns: {product_cols_to_rename}\")\n",
    "\n",
    "    # Drop the other set (_y columns)\n",
    "    product_cols_exist_to_drop = [col for col in product_cols_to_drop if col in filtered_orders.columns]\n",
    "    if product_cols_exist_to_drop:\n",
    "        filtered_orders = filtered_orders.drop(columns=product_cols_exist_to_drop)\n",
    "        print(f\"Dropped unused product columns: {product_cols_exist_to_drop}\")\n",
    "else:\n",
    "     # Check if columns already exist without suffix (maybe fixed earlier?)\n",
    "     if 'product_size_cm3' in filtered_orders.columns and 'product_weight_g' in filtered_orders.columns:\n",
    "         print(\"Product columns seem to already have correct names (no _x/_y suffix).\")\n",
    "     else:\n",
    "         print(\"Warning: Could not find product columns with _x suffix to rename.\")\n",
    "\n",
    "\n",
    "# --- Step 3: Rename Geolocation State Columns ---\n",
    "print(\"\\n--- Step 3: Renaming geolocation state columns ---\")\n",
    "# Assuming _x = seller, _y = customer based on common patterns\n",
    "geo_state_rename_map = {\n",
    "    'geolocation_state_x': 'geolocation_state_seller',\n",
    "    'geolocation_state_y': 'geolocation_state_customer'\n",
    "}\n",
    "# Check if _x/_y columns exist for renaming\n",
    "geo_cols_to_rename = {k: v for k, v in geo_state_rename_map.items() if k in filtered_orders.columns}\n",
    "if geo_cols_to_rename:\n",
    "    filtered_orders = filtered_orders.rename(columns=geo_cols_to_rename)\n",
    "    print(f\"Renamed geolocation state columns: {geo_cols_to_rename}\")\n",
    "else:\n",
    "    # Check if columns already exist with seller/customer names\n",
    "     if 'geolocation_state_seller' in filtered_orders.columns and 'geolocation_state_customer' in filtered_orders.columns:\n",
    "         print(\"Geolocation state columns seem to already have correct names (seller/customer).\")\n",
    "     else:\n",
    "        print(\"Warning: Could not find geolocation state columns with _x/_y suffix to rename.\")\n",
    "\n",
    "\n",
    "# ========== NOW START THE MAIN PROCESSING BLOCK ==========\n",
    "# The DataFrame should now be cleaned up and ready for calculations.\n",
    "\n",
    "print(\"\\n--- Starting Main Processing Block ---\")\n",
    "\n",
    "# --- Calculate Haversine distance ---\n",
    "# Uses _x/_y directly as state columns were renamed, but lat/lon weren't necessarily\n",
    "print(\"Calculating Haversine distance...\")\n",
    "required_dist_cols = ['geolocation_lng_x', 'geolocation_lat_x', 'geolocation_lng_y', 'geolocation_lat_y']\n",
    "if all(col in filtered_orders.columns for col in required_dist_cols):\n",
    "    filtered_orders['distance'] = filtered_orders.apply(\n",
    "        lambda row: haversine_distance(\n",
    "            row[\"geolocation_lng_x\"], row[\"geolocation_lat_x\"],\n",
    "            row[\"geolocation_lng_y\"], row[\"geolocation_lat_y\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    print(\"Distance calculation complete.\")\n",
    "else:\n",
    "    print(f\"Warning: Could not calculate distance. Missing one or more columns from: {required_dist_cols}\")\n",
    "    filtered_orders['distance'] = np.nan\n",
    "\n",
    "\n",
    "# --- Merge Package Info ---\n",
    "# NOTE: This seems redundant if product columns were already present with _x/_y suffixes.\n",
    "# You might need to revisit if/how this merge should happen.\n",
    "# If product info came from an earlier merge, you might skip this.\n",
    "# print(\"Merging package size/weight...\")\n",
    "# orders_size_weight = get_package_size(items, products)\n",
    "# filtered_orders = filtered_orders.merge(orders_size_weight, on='order_id', how='left')\n",
    "# print(\"Package info merge complete.\")\n",
    "# --> Skipping this merge for now, assuming product info is already present from the _x cols\n",
    "\n",
    "\n",
    "# --- Process time columns ---\n",
    "print(\"Converting time columns...\")\n",
    "time_columns = ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "conversion_successful = True\n",
    "for column in time_columns:\n",
    "    if column in filtered_orders.columns:\n",
    "        # Ensure it's not already datetime64\n",
    "        if not pd.api.types.is_datetime64_any_dtype(filtered_orders[column]):\n",
    "             filtered_orders.loc[:, column] = pd.to_datetime(filtered_orders[column], errors='coerce')\n",
    "             if filtered_orders[column].isna().all():\n",
    "                 print(f\"Warning: Column '{column}' became all NaT after conversion.\")\n",
    "                 conversion_successful = False\n",
    "        else:\n",
    "             print(f\"Column '{column}' is already datetime type.\")\n",
    "    else:\n",
    "        print(f\"Warning: Time column '{column}' not found.\")\n",
    "        conversion_successful = False\n",
    "if conversion_successful:\n",
    "    print(\"Time column conversion complete.\")\n",
    "else:\n",
    "    print(\"Time column conversion may have failed or columns were missing.\")\n",
    "\n",
    "\n",
    "# --- Calculate Wait Times ---\n",
    "print(\"Calculating wait times...\")\n",
    "if ('order_delivered_customer_date' in filtered_orders.columns and\n",
    "    'order_purchase_timestamp' in filtered_orders.columns and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_delivered_customer_date']) and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_purchase_timestamp'])):\n",
    "    filtered_orders.loc[:, \"wait_time\"] = (filtered_orders['order_delivered_customer_date'] - filtered_orders['order_purchase_timestamp']).dt.days\n",
    "else:\n",
    "    print(\"Warning: Cannot calculate actual wait time.\")\n",
    "    if \"wait_time\" not in filtered_orders.columns: filtered_orders.loc[:, \"wait_time\"] = np.nan\n",
    "\n",
    "if ('order_estimated_delivery_date' in filtered_orders.columns and\n",
    "    'order_purchase_timestamp' in filtered_orders.columns and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_estimated_delivery_date']) and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_purchase_timestamp'])):\n",
    "    filtered_orders.loc[:, \"est_wait_time\"] = (filtered_orders['order_estimated_delivery_date'] - filtered_orders['order_purchase_timestamp']).dt.days\n",
    "else:\n",
    "    print(\"Warning: Cannot calculate estimated wait time.\")\n",
    "    if \"est_wait_time\" not in filtered_orders.columns: filtered_orders.loc[:, \"est_wait_time\"] = np.nan\n",
    "\n",
    "\n",
    "# --- Extract Date Components ---\n",
    "print(\"Extracting date components...\")\n",
    "if ('order_purchase_timestamp' in filtered_orders.columns and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_purchase_timestamp'])):\n",
    "    filtered_orders.loc[:, \"purchase_dow\"] = filtered_orders.order_purchase_timestamp.dt.dayofweek\n",
    "    filtered_orders.loc[:, \"year\"] = filtered_orders.order_purchase_timestamp.dt.year\n",
    "    filtered_orders.loc[:, \"purchase_month\"] = filtered_orders.order_purchase_timestamp.dt.month\n",
    "else:\n",
    "    print(\"Warning: Cannot extract date components.\")\n",
    "    if \"purchase_dow\" not in filtered_orders.columns: filtered_orders.loc[:, \"purchase_dow\"] = np.nan\n",
    "    if \"year\" not in filtered_orders.columns: filtered_orders.loc[:, \"year\"] = np.nan\n",
    "    if \"purchase_month\" not in filtered_orders.columns: filtered_orders.loc[:, \"purchase_month\"] = np.nan\n",
    "\n",
    "\n",
    "# --- Create Final DataFrame ---\n",
    "print(\"Creating final DataFrame...\")\n",
    "# Use the cleaned/renamed column names\n",
    "final_columns_needed = [\n",
    "    'purchase_dow', 'purchase_month', 'year',\n",
    "    'product_size_cm3', 'product_weight_g', # Expecting these after renaming _x\n",
    "    'geolocation_state_customer', # Expecting these after renaming _y\n",
    "    'geolocation_state_seller',   # Expecting these after renaming _x\n",
    "    'distance',\n",
    "    'wait_time', 'est_wait_time'\n",
    "]\n",
    "final_columns_present = [col for col in final_columns_needed if col in filtered_orders.columns]\n",
    "missing_final_cols = set(final_columns_needed) - set(final_columns_present)\n",
    "if missing_final_cols:\n",
    "    print(f\"Warning: Columns still missing for final_df: {missing_final_cols}\")\n",
    "\n",
    "final_df = filtered_orders[final_columns_present].copy()\n",
    "\n",
    "\n",
    "# --- Calculate Delay Feature ---\n",
    "print(\"Calculating delay feature...\")\n",
    "if 'wait_time' in final_df.columns and 'est_wait_time' in final_df.columns:\n",
    "    delay_diff = (final_df['wait_time'] - final_df['est_wait_time']).fillna(0)\n",
    "    final_df['delay'] = (delay_diff > 0).astype(int)\n",
    "else:\n",
    "    print(\"Warning: Cannot calculate delay feature.\")\n",
    "    final_df['delay'] = 0\n",
    "\n",
    "\n",
    "# --- Encode Final DataFrame ---\n",
    "print(\"Encoding object columns...\")\n",
    "final_df_enc = final_df.apply(lambda x: object_to_int(x))\n",
    "\n",
    "\n",
    "# --- Display results ---\n",
    "print(\"\\nFirst 5 rows of the final encoded DataFrame (final_df_enc):\")\n",
    "print(final_df_enc.head())\n",
    "print(\"\\nFinal DataFrame Info:\")\n",
    "print(final_df_enc.info())\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "627b4690-4a32-481e-8744-d86e299dc22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Main Processing Block ---\n",
      "Converting time columns...\n",
      "Time column conversion attempt finished.\n",
      "\n",
      "--- Checking Time Columns AFTER Conversion ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106578 entries, 0 to 106577\n",
      "Data columns (total 3 columns):\n",
      " #   Column                         Non-Null Count   Dtype \n",
      "---  ------                         --------------   ----- \n",
      " 0   order_purchase_timestamp       106578 non-null  object\n",
      " 1   order_delivered_customer_date  106578 non-null  object\n",
      " 2   order_estimated_delivery_date  106578 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "\n",
      "Head of time columns:\n",
      "  order_purchase_timestamp order_delivered_customer_date  \\\n",
      "0      2017-10-02 10:56:33           2017-10-10 21:25:13   \n",
      "1      2018-07-24 20:41:37           2018-08-07 15:27:45   \n",
      "2      2018-08-08 08:38:49           2018-08-17 18:06:29   \n",
      "3      2017-11-18 19:28:06           2017-12-02 00:28:42   \n",
      "4      2018-02-13 21:18:39           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0           2017-10-18 00:00:00  \n",
      "1           2018-08-13 00:00:00  \n",
      "2           2018-09-04 00:00:00  \n",
      "3           2017-12-15 00:00:00  \n",
      "4           2018-02-26 00:00:00  \n",
      "\n",
      "Null/NaT counts in time columns:\n",
      "order_purchase_timestamp         0\n",
      "order_delivered_customer_date    0\n",
      "order_estimated_delivery_date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# [Previous code: Initial state check, Steps 1, 2, 3]\n",
    "# ... (Cleanup steps as before) ...\n",
    "\n",
    "print(\"\\n--- Starting Main Processing Block ---\")\n",
    "\n",
    "# ... (Distance Calculation as before) ...\n",
    "\n",
    "# --- Process time columns ---\n",
    "print(\"Converting time columns...\")\n",
    "time_columns = ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "conversion_successful = True\n",
    "for column in time_columns:\n",
    "    if column in filtered_orders.columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(filtered_orders[column]):\n",
    "             filtered_orders.loc[:, column] = pd.to_datetime(filtered_orders[column], errors='coerce')\n",
    "             # Check right after conversion if ALL values became NaT\n",
    "             if filtered_orders[column].isna().all():\n",
    "                 print(f\"----> CRITICAL WARNING: Column '{column}' is ALL NaT values after conversion!\")\n",
    "                 conversion_successful = False\n",
    "             elif filtered_orders[column].isna().any():\n",
    "                 print(f\"----> NOTE: Column '{column}' has SOME NaT values after conversion.\")\n",
    "        else:\n",
    "             print(f\"Column '{column}' is already datetime type.\")\n",
    "    else:\n",
    "        print(f\"Warning: Time column '{column}' not found.\")\n",
    "        conversion_successful = False\n",
    "\n",
    "if conversion_successful:\n",
    "    print(\"Time column conversion attempt finished.\")\n",
    "else:\n",
    "    print(\"Time column conversion may have failed or columns were missing/invalid.\")\n",
    "\n",
    "# ***** ADD THIS DEBUGGING BLOCK *****\n",
    "print(\"\\n--- Checking Time Columns AFTER Conversion ---\")\n",
    "if all(col in filtered_orders.columns for col in time_columns):\n",
    "    print(filtered_orders[time_columns].info())\n",
    "    print(\"\\nHead of time columns:\")\n",
    "    print(filtered_orders[time_columns].head())\n",
    "    print(\"\\nNull/NaT counts in time columns:\")\n",
    "    print(filtered_orders[time_columns].isna().sum())\n",
    "else:\n",
    "    print(\"One or more time columns are missing, cannot debug their state.\")\n",
    "# ***********************************\n",
    "\n",
    "# --- Calculate Wait Times ---\n",
    "# ... (rest of the code remains the same) ...\n",
    "# ... (wait time calc, date components, final_df, delay, encode, print head/info) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbfcf7bf-e854-4642-b5be-6c83f6cede8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting time columns...\n",
      "Attempting conversion for: order_purchase_timestamp\n",
      " -> Success: 'order_purchase_timestamp' dtype is now datetime64[ns]\n",
      "Attempting conversion for: order_delivered_customer_date\n",
      " -> Success: 'order_delivered_customer_date' dtype is now datetime64[ns]\n",
      "Attempting conversion for: order_estimated_delivery_date\n",
      " -> Success: 'order_estimated_delivery_date' dtype is now datetime64[ns]\n",
      "Time column conversion attempt finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Process time columns (REVISED ASSIGNMENT) ---\n",
    "print(\"Converting time columns...\")\n",
    "time_columns = ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "conversion_successful = True\n",
    "for column in time_columns:\n",
    "    if column in filtered_orders.columns:\n",
    "        # Ensure it's not already datetime64 before attempting conversion\n",
    "        if not pd.api.types.is_datetime64_any_dtype(filtered_orders[column]):\n",
    "            print(f\"Attempting conversion for: {column}\")\n",
    "            # MODIFICATION: Use direct assignment instead of .loc\n",
    "            converted_column = pd.to_datetime(filtered_orders[column], errors='coerce')\n",
    "            filtered_orders[column] = converted_column # Assign back using bracket notation\n",
    "\n",
    "            # Check results AFTER assignment\n",
    "            if pd.api.types.is_datetime64_any_dtype(filtered_orders[column]):\n",
    "                 print(f\" -> Success: '{column}' dtype is now {filtered_orders[column].dtype}\")\n",
    "                 if filtered_orders[column].isna().all():\n",
    "                    print(f\"    ----> CRITICAL WARNING: Column '{column}' is ALL NaT values after conversion!\")\n",
    "                    conversion_successful = False\n",
    "                 elif filtered_orders[column].isna().any():\n",
    "                    print(f\"    ----> NOTE: Column '{column}' has SOME NaT values after conversion.\")\n",
    "            else:\n",
    "                 print(f\" -> FAILURE: '{column}' dtype is still {filtered_orders[column].dtype}\")\n",
    "                 conversion_successful = False\n",
    "        else:\n",
    "             print(f\"Column '{column}' is already datetime type.\")\n",
    "    else:\n",
    "        print(f\"Warning: Time column '{column}' not found.\")\n",
    "        conversion_successful = False\n",
    "\n",
    "if conversion_successful:\n",
    "    print(\"Time column conversion attempt finished.\")\n",
    "else:\n",
    "    print(\"Time column conversion FAILED for one or more columns.\")\n",
    "\n",
    "# ***** REMOVE or COMMENT OUT the Debugging Block from the previous step *****\n",
    "# print(\"\\n--- Checking Time Columns AFTER Conversion ---\")\n",
    "# ... (remove the .info(), .head(), .isna() checks here) ...\n",
    "# ************************************************************************\n",
    "\n",
    "# --- Calculate Wait Times ---\n",
    "# ... (rest of the code remains the same) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e637e21b-b862-4b8a-9bb7-97bcefe24351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jashp\\AppData\\Local\\Temp\\ipykernel_9776\\3744644978.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  filtered_orders['distance'].fillna(0, inplace=True)\n",
      "C:\\Users\\jashp\\AppData\\Local\\Temp\\ipykernel_9776\\1260564690.py:56: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_object_dtype(series) or pd.api.types.is_categorical_dtype(series):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical column: geolocation_state_customer\n",
      "Encoding categorical column: geolocation_state_seller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jashp\\AppData\\Local\\Temp\\ipykernel_9776\\1260564690.py:56: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_object_dtype(series) or pd.api.types.is_categorical_dtype(series):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_dow</th>\n",
       "      <th>purchase_month</th>\n",
       "      <th>year</th>\n",
       "      <th>product_size_cm3</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>geolocation_state_customer</th>\n",
       "      <th>geolocation_state_seller</th>\n",
       "      <th>distance</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>est_wait_time</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>4693.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>9576.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>11475.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_dow  purchase_month  year  product_size_cm3  product_weight_g  \\\n",
       "0             0              10  2017            1976.0             500.0   \n",
       "1             1               7  2018            4693.0             400.0   \n",
       "2             2               8  2018            9576.0             420.0   \n",
       "3             5              11  2017            6000.0             450.0   \n",
       "4             1               2  2018           11475.0             250.0   \n",
       "\n",
       "   geolocation_state_customer  geolocation_state_seller  distance  wait_time  \\\n",
       "0                           0                         0       0.0          8   \n",
       "1                           1                         1       0.0         13   \n",
       "2                           0                         0       0.0          9   \n",
       "3                           1                         1       0.0         13   \n",
       "4                           0                         0       0.0          2   \n",
       "\n",
       "   est_wait_time  delay  \n",
       "0             15      0  \n",
       "1             19      0  \n",
       "2             26      0  \n",
       "3             26      0  \n",
       "4             12      0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume filtered_orders, items, products DataFrames are loaded\n",
    "# Assume haversine_distance, get_package_size, object_to_int functions are defined\n",
    "\n",
    "# --- Calculate Distance ---\n",
    "required_dist_cols = ['geolocation_lng_x', 'geolocation_lat_x', 'geolocation_lng_y', 'geolocation_lat_y']\n",
    "if all(col in filtered_orders.columns for col in required_dist_cols):\n",
    "    for col in required_dist_cols:\n",
    "        filtered_orders[col] = pd.to_numeric(filtered_orders[col], errors='coerce')\n",
    "    filtered_orders_no_nan_geo = filtered_orders.dropna(subset=required_dist_cols)\n",
    "    distances = filtered_orders_no_nan_geo.apply(\n",
    "        lambda row: haversine_distance(\n",
    "            row[\"geolocation_lng_x\"], row[\"geolocation_lat_x\"],\n",
    "            row[\"geolocation_lng_y\"], row[\"geolocation_lat_y\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    filtered_orders['distance'] = distances\n",
    "    filtered_orders['distance'].fillna(0, inplace=True)\n",
    "else:\n",
    "    filtered_orders['distance'] = 0.0\n",
    "# This line creates a new column in the filtered_orders DataFrame called \"distance\" by applying the haversine_distance function to calculate the distance between the seller and the customer for each row in the DataFrame.\n",
    "\n",
    "\n",
    "# --- Merge Package Info ---\n",
    "orders_size_weight = get_package_size(items, products)\n",
    "if not orders_size_weight.empty:\n",
    "    if 'product_size_cm3' in orders_size_weight.columns and 'product_weight_g' in orders_size_weight.columns:\n",
    "         filtered_orders = filtered_orders.merge(orders_size_weight[['order_id', 'product_size_cm3', 'product_weight_g']], on='order_id', how='left')\n",
    "    else:\n",
    "        if 'product_size_cm3' not in filtered_orders.columns: filtered_orders['product_size_cm3'] = np.nan\n",
    "        if 'product_weight_g' not in filtered_orders.columns: filtered_orders['product_weight_g'] = np.nan\n",
    "else:\n",
    "    if 'product_size_cm3' not in filtered_orders.columns: filtered_orders['product_size_cm3'] = np.nan\n",
    "    if 'product_weight_g' not in filtered_orders.columns: filtered_orders['product_weight_g'] = np.nan\n",
    "# These lines merge information about the package size and weight for each order from the items and products DataFrames into the filtered_orders DataFrame.\n",
    "\n",
    "\n",
    "# --- Process time columns ---\n",
    "time_columns = ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "for column in time_columns:\n",
    "    if column in filtered_orders.columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(filtered_orders[column]):\n",
    "            # Use direct assignment\n",
    "            filtered_orders[column] = pd.to_datetime(filtered_orders[column], errors='coerce')\n",
    "    else:\n",
    "         filtered_orders[column] = pd.NaT\n",
    "# These lines convert several time-related columns in the filtered_orders DataFrame from string format to datetime format using the pd.to_datetime function.\n",
    "\n",
    "\n",
    "# --- Calculate Wait Times ---\n",
    "if ('order_delivered_customer_date' in filtered_orders.columns and\n",
    "    'order_purchase_timestamp' in filtered_orders.columns and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_delivered_customer_date']) and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_purchase_timestamp'])):\n",
    "    filtered_orders[\"wait_time\"] = (filtered_orders['order_delivered_customer_date'] - filtered_orders['order_purchase_timestamp']).dt.days\n",
    "else:\n",
    "    filtered_orders[\"wait_time\"] = np.nan\n",
    "\n",
    "if ('order_estimated_delivery_date' in filtered_orders.columns and\n",
    "    'order_purchase_timestamp' in filtered_orders.columns and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_estimated_delivery_date']) and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_purchase_timestamp'])):\n",
    "    filtered_orders[\"est_wait_time\"] = (filtered_orders['order_estimated_delivery_date'] - filtered_orders['order_purchase_timestamp']).dt.days\n",
    "else:\n",
    "    filtered_orders[\"est_wait_time\"] = np.nan\n",
    "# These lines calculate the wait time and estimated wait time for each order in days, based on the difference between the purchase time and the delivered/estimated delivery time.\n",
    "\n",
    "\n",
    "# --- Extract Date Components ---\n",
    "if ('order_purchase_timestamp' in filtered_orders.columns and\n",
    "    pd.api.types.is_datetime64_any_dtype(filtered_orders['order_purchase_timestamp'])):\n",
    "    filtered_orders[\"purchase_dow\"] = filtered_orders.order_purchase_timestamp.dt.dayofweek\n",
    "    filtered_orders[\"year\"] = filtered_orders.order_purchase_timestamp.dt.year\n",
    "    filtered_orders[\"purchase_month\"] = filtered_orders.order_purchase_timestamp.dt.month\n",
    "else:\n",
    "    filtered_orders[\"purchase_dow\"] = np.nan\n",
    "    filtered_orders[\"year\"] = np.nan\n",
    "    filtered_orders[\"purchase_month\"] = np.nan\n",
    "# These lines extract the day of the week, year, and month from the order_purchase_timestamp column in the filtered_orders DataFrame.\n",
    "\n",
    "\n",
    "# --- Rename Geolocation State Columns (Necessary before final selection) ---\n",
    "geo_state_rename_map = {\n",
    "    'geolocation_state_x': 'geolocation_state_seller',\n",
    "    'geolocation_state_y': 'geolocation_state_customer'\n",
    "}\n",
    "geo_cols_to_rename = {k: v for k, v in geo_state_rename_map.items() if k in filtered_orders.columns}\n",
    "if geo_cols_to_rename:\n",
    "    filtered_orders = filtered_orders.rename(columns=geo_cols_to_rename)\n",
    "\n",
    "\n",
    "# --- Create Final DataFrame ---\n",
    "final_columns_needed = [\n",
    "    'purchase_dow', 'purchase_month', 'year',\n",
    "    'product_size_cm3', 'product_weight_g',\n",
    "    'geolocation_state_customer', # Expecting these after renaming\n",
    "    'geolocation_state_seller',   # Expecting these after renaming\n",
    "    'distance',\n",
    "    'wait_time', 'est_wait_time'\n",
    "]\n",
    "for col in final_columns_needed:\n",
    "    if col not in filtered_orders.columns:\n",
    "        filtered_orders[col] = np.nan\n",
    "final_df = filtered_orders[final_columns_needed].copy()\n",
    "# This line creates a new DataFrame called final_df by selecting certain columns from the filtered_orders DataFrame.\n",
    "\n",
    "\n",
    "# --- Calculate Delay Feature ---\n",
    "if 'wait_time' in final_df.columns and 'est_wait_time' in final_df.columns:\n",
    "    delay_diff = (final_df['wait_time'] - final_df['est_wait_time']).fillna(0)\n",
    "    final_df['delay'] = (delay_diff > 0).astype(int)\n",
    "else:\n",
    "    final_df['delay'] = 0\n",
    "# These lines calculate the delay time for each order and encode it as a binary variable indicating whether there was a delay or not.\n",
    "\n",
    "\n",
    "# --- Encode Final DataFrame ---\n",
    "final_df_enc = final_df.apply(lambda x: object_to_int(x), axis=0)\n",
    "# This line applies the object_to_int function to each column in the final_df DataFrame to convert categorical variables into integer format. The object_to_int function is not shown in the code provided, but it likely uses the LabelEncoder class from the scikit-learn library to perform the conversion.\n",
    "\n",
    "\n",
    "# --- Display Final Output ---\n",
    "final_df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c73639c3-4c3e-4328-b94e-a4d4ce2a3265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully exported 'final_OTD_time_forecasting_dataframe.csv'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    final_df_enc.to_csv('final_OTD_time_forecasting_dataframe.csv', index=False)\n",
    "    print(\"\\nSuccessfully exported 'final_OTD_time_forecasting_dataframe.csv'\") # Success message\n",
    "except Exception as e:\n",
    "    print(f\"\\nError exporting CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a66e0-033e-4ac6-8ab8-0c0dfccc1c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
