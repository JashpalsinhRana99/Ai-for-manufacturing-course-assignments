{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acc38f3-e356-4fe3-a278-4390a5f093d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in e:\\anaconda\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b69fbd-14b1-4d70-a87b-85453841e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, asin, sqrt\n",
    "# This line imports specific functions from the math library that are used for calculating the haversine distance between two points on a globe.\n",
    "\n",
    "import pandas as pd\n",
    "# This line imports the Pandas library, which is a popular library for data manipulation and analysis.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# This line imports the LabelEncoder and StandardScaler classes from the scikit-learn library, which are used for preprocessing data for machine learning models.\n",
    "\n",
    "import time\n",
    "# This line imports the time module, which is used for timing the execution of code\n",
    "\n",
    "import numpy as np\n",
    "# This line imports the NumPy library, which provides support for numerical computing with Python.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# This line imports the accuracy_score function from the scikit-learn library, which is used for evaluating the performance of classification models.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# These lines import the train_test_split and GridSearchCV classes from the scikit-learn library, which are used for splitting data into training and testing sets and tuning hyperparameters, respectively.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "# These lines import the RandomForestRegressor, VotingRegressor, and SVR classes from the scikit-learn library, which are used for building machine learning models.\n",
    "\n",
    "import xgboost as xgb\n",
    "# This line imports the xgboost library, which is a popular library for gradient boosting.\n",
    "\n",
    "import pickle\n",
    "# This line imports the pickle module, which is used for serializing and deserializing Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc40814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, asin, sqrt\n",
    "# This line imports specific functions from the math library that are used for calculating the haversine distance between two points on a globe.\n",
    "\n",
    "import pandas as pd\n",
    "# This line imports the Pandas library, which is a popular library for data manipulation and analysis.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# This line imports the LabelEncoder and StandardScaler classes from the scikit-learn library, which are used for preprocessing data for machine learning models.\n",
    "\n",
    "import time\n",
    "# This line imports the time module, which is used for timing the execution of code\n",
    "\n",
    "import numpy as np\n",
    "# This line imports the NumPy library, which provides support for numerical computing with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6856bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv(\"./data/olist_orders_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_orders_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"orders\".\n",
    "\n",
    "items = pd.read_csv(\"./data/olist_order_items_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_order_items_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"items\".\n",
    "\n",
    "customers = pd.read_csv(\"./data/olist_customers_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_customers_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"customers\".\n",
    "\n",
    "sellers = pd.read_csv(\"./data/olist_sellers_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_sellers_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"sellers\".\n",
    "\n",
    "geo = pd.read_csv(\"./data/olist_geolocation_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_geolocation_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"geo\".\n",
    "\n",
    "products = pd.read_csv(\"./data/olist_products_dataset.csv\")\n",
    "# This line reads the CSV file \"olist_products_dataset.csv\" located in the \"./data/\" directory and stores its contents as a Pandas DataFrame named \"products\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18bae66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.head()\n",
    "\n",
    "# The code above assumes that a Pandas DataFrame named orders has been previously defined, and calls the head() method on that DataFrame.\n",
    "\n",
    "# The head() method is used to display the first few rows of a DataFrame, by default the first five rows. This can be useful for quickly checking the structure and content of a DataFrame.\n",
    "\n",
    "# So, this line of code will output the first five rows of the orders DataFrame, assuming it has been previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2446310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cef67bcfe19066a932b7673e239eb23d</td>\n",
       "      <td>bebes</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9dc1a7de274444849c219cff195d0b71</td>\n",
       "      <td>utilidades_domesticas</td>\n",
       "      <td>37.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
       "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
       "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "0                 40.0                       287.0                 1.0   \n",
       "1                 44.0                       276.0                 1.0   \n",
       "2                 46.0                       250.0                 1.0   \n",
       "3                 27.0                       261.0                 1.0   \n",
       "4                 37.0                       402.0                 4.0   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
       "0             225.0               16.0               10.0              14.0  \n",
       "1            1000.0               30.0               18.0              20.0  \n",
       "2             154.0               18.0                9.0              15.0  \n",
       "3             371.0               26.0                4.0              26.0  \n",
       "4             625.0               20.0               17.0              13.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec3cebe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29963cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "551fb82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# info() helps summarize the dataset- It gives basic information like number of non-null values, datatypes and memory usage\n",
    "# It is a good practise to start by this information\n",
    "products.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52dbf7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d05b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sellers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c84e24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61f72e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date                         seller_id  \\\n",
       "0           2017-10-18 00:00:00  3504c0cb71d7fa48d967e0e4c94d59d9   \n",
       "1           2018-08-13 00:00:00  289cdb325fb7e7f891c38608bf9e0962   \n",
       "2           2018-09-04 00:00:00  4869f7a5dfa277a7dca6462dcf3b52b2   \n",
       "3           2017-12-15 00:00:00  66922902710d126a0e7d26b0e3805106   \n",
       "4           2018-02-26 00:00:00  2c9e548be18521d1c43cde1c582c6de8   \n",
       "\n",
       "   seller_zip_code_prefix  \n",
       "0                  9350.0  \n",
       "1                 31570.0  \n",
       "2                 14840.0  \n",
       "3                 31842.0  \n",
       "4                  8752.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the seller zip code of each order\n",
    "\n",
    "middle = items[['order_id', 'seller_id']]\n",
    "# This line creates a new dataframe middle that contains only the order_id and seller_id columns from the items dataframe.\n",
    "\n",
    "middle_2 = middle.merge(sellers[['seller_id', 'seller_zip_code_prefix']], on=\"seller_id\", how=\"outer\")\n",
    "# This line merges the middle dataframe with the seller_id and seller_zip_code_prefix columns from the sellers dataframe, creating a new dataframe middle_2. The outer join type is used, which means that all rows from both dataframes are included in the merged dataframe, and missing values are filled with NaN.\n",
    "\n",
    "orders = orders.merge(middle_2, on=\"order_id\", how=\"left\")\n",
    "# This line merges the orders dataframe with the middle_2 dataframe on the order_id column, creating a new orders dataframe. The left join type is used, which means that all rows from the orders dataframe are included in the merged dataframe, and missing values from the middle_2 dataframe are filled with NaN.\n",
    "\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03774037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>3149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>47813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>75265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>59296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>9195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date                         seller_id  \\\n",
       "0           2017-10-18 00:00:00  3504c0cb71d7fa48d967e0e4c94d59d9   \n",
       "1           2018-08-13 00:00:00  289cdb325fb7e7f891c38608bf9e0962   \n",
       "2           2018-09-04 00:00:00  4869f7a5dfa277a7dca6462dcf3b52b2   \n",
       "3           2017-12-15 00:00:00  66922902710d126a0e7d26b0e3805106   \n",
       "4           2018-02-26 00:00:00  2c9e548be18521d1c43cde1c582c6de8   \n",
       "\n",
       "   seller_zip_code_prefix  customer_zip_code_prefix  \n",
       "0                  9350.0                      3149  \n",
       "1                 31570.0                     47813  \n",
       "2                 14840.0                     75265  \n",
       "3                 31842.0                     59296  \n",
       "4                  8752.0                      9195  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get customer zip code of each order\n",
    "orders = orders.merge(customers[['customer_id', 'customer_zip_code_prefix']],\n",
    "                  on='customer_id', how=\"left\")\n",
    "# The code above performs a left merge operation between two Pandas dataframes named \"orders\" and \"customers\" using the \"customer_id\" column as the joining key. It then selects the \"customer_id\" and \"customer_zip_code_prefix\" columns from the \"customers\" dataframe and merges them with the \"orders\" dataframe based on the matching \"customer_id\" column.\n",
    "\n",
    "\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ca640b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>-23.545621</td>\n",
       "      <td>-46.639292</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546081</td>\n",
       "      <td>-46.644820</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041</td>\n",
       "      <td>-23.544392</td>\n",
       "      <td>-46.639499</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>-23.541578</td>\n",
       "      <td>-46.641607</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1012</td>\n",
       "      <td>-23.547762</td>\n",
       "      <td>-46.635361</td>\n",
       "      <td>são paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                         1037       -23.545621       -46.639292   \n",
       "1                         1046       -23.546081       -46.644820   \n",
       "3                         1041       -23.544392       -46.639499   \n",
       "4                         1035       -23.541578       -46.641607   \n",
       "5                         1012       -23.547762       -46.635361   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0        sao paulo                SP  \n",
       "1        sao paulo                SP  \n",
       "3        sao paulo                SP  \n",
       "4        sao paulo                SP  \n",
       "5        são paulo                SP  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean geo df\n",
    "geo = geo[~geo['geolocation_zip_code_prefix'].duplicated()]\n",
    "'''\n",
    "This line first selects the 'geolocation_zip_code_prefix' column from the 'geo' DataFrame using the indexing operator []. The duplicated() method is then called on this column to create a boolean mask of rows that have duplicate values in this column.\n",
    "\n",
    "The tilde operator (~) is used to invert this boolean mask, so that the mask contains True for rows that do not have duplicate values in this column.\n",
    "'''\n",
    "\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c8e8fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>3149</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>-23.680114</td>\n",
       "      <td>-46.452454</td>\n",
       "      <td>maua</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>47813</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>-19.810119</td>\n",
       "      <td>-43.984727</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>75265</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>-21.362358</td>\n",
       "      <td>-48.232976</td>\n",
       "      <td>guariba</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>59296</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>-19.840168</td>\n",
       "      <td>-43.923299</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>9195</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>-23.551707</td>\n",
       "      <td>-46.260979</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date                         seller_id  \\\n",
       "0           2017-10-18 00:00:00  3504c0cb71d7fa48d967e0e4c94d59d9   \n",
       "1           2018-08-13 00:00:00  289cdb325fb7e7f891c38608bf9e0962   \n",
       "2           2018-09-04 00:00:00  4869f7a5dfa277a7dca6462dcf3b52b2   \n",
       "3           2017-12-15 00:00:00  66922902710d126a0e7d26b0e3805106   \n",
       "4           2018-02-26 00:00:00  2c9e548be18521d1c43cde1c582c6de8   \n",
       "\n",
       "   seller_zip_code_prefix  customer_zip_code_prefix  \\\n",
       "0                  9350.0                      3149   \n",
       "1                 31570.0                     47813   \n",
       "2                 14840.0                     75265   \n",
       "3                 31842.0                     59296   \n",
       "4                  8752.0                      9195   \n",
       "\n",
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                       9350.0       -23.680114       -46.452454   \n",
       "1                      31570.0       -19.810119       -43.984727   \n",
       "2                      14840.0       -21.362358       -48.232976   \n",
       "3                      31842.0       -19.840168       -43.923299   \n",
       "4                       8752.0       -23.551707       -46.260979   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0             maua                SP  \n",
       "1   belo horizonte                MG  \n",
       "2          guariba                SP  \n",
       "3   belo horizonte                MG  \n",
       "4  mogi das cruzes                SP  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add seller coordinates to the orders\n",
    "orders = orders.merge(geo, left_on=\"seller_zip_code_prefix\",\n",
    "                      right_on=\"geolocation_zip_code_prefix\", how=\"left\")\n",
    "'''\n",
    "The code above performs a left join of two dataframes - \"orders\" and \"geo\" - using the \"seller_zip_code_prefix\" column of the \"orders\" dataframe and the \"geolocation_zip_code_prefix\" column of the \"geo\" dataframe as the join keys.\n",
    "'''\n",
    "                      \n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "060d3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add customer coordinates to the orders\n",
    "orders = orders.merge(geo, left_on=\"customer_zip_code_prefix\",\n",
    "                      right_on=\"geolocation_zip_code_prefix\", how=\"left\",\n",
    "                      suffixes=(\"_seller\", \"_customer\"))\n",
    "# This code merges two Pandas DataFrames, orders and geo, on a common column, customer_zip_code_prefix in orders and geolocation_zip_code_prefix in geo. The resulting merged DataFrame contains all the columns from both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90635477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean orders\n",
    "# 1-Filter out orders with multiple sellers Because each order only has one delivery date\n",
    "df = orders.groupby(by=\"order_id\").nunique()\n",
    "# Groups the orders by order_id and calculates the number of unique values in each group using the nunique() method.\n",
    "\n",
    "mono_orders = pd.Series(df[df['seller_id'] == 1].index)\n",
    "# Selects the indices of the resulting DataFrame where the seller_id column equals 1 and stores them in a Pandas Series called mono_orders.\n",
    "\n",
    "filtered_orders = orders.merge(mono_orders, how='inner')\n",
    "# Merges the original orders DataFrame with mono_orders based on the order_id column using an inner join and stores the resulting DataFrame in a variable called filtered_orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b5b6f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>geolocation_zip_code_prefix_seller</th>\n",
       "      <th>geolocation_lat_seller</th>\n",
       "      <th>geolocation_lng_seller</th>\n",
       "      <th>geolocation_city_seller</th>\n",
       "      <th>geolocation_state_seller</th>\n",
       "      <th>geolocation_zip_code_prefix_customer</th>\n",
       "      <th>geolocation_lat_customer</th>\n",
       "      <th>geolocation_lng_customer</th>\n",
       "      <th>geolocation_city_customer</th>\n",
       "      <th>geolocation_state_customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>3504c0cb71d7fa48d967e0e4c94d59d9</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>3149</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>-23.680114</td>\n",
       "      <td>-46.452454</td>\n",
       "      <td>maua</td>\n",
       "      <td>SP</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>-23.574809</td>\n",
       "      <td>-46.587471</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>289cdb325fb7e7f891c38608bf9e0962</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>47813</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>-19.810119</td>\n",
       "      <td>-43.984727</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>47813.0</td>\n",
       "      <td>-12.169860</td>\n",
       "      <td>-44.988369</td>\n",
       "      <td>barreiras</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>4869f7a5dfa277a7dca6462dcf3b52b2</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>75265</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>-21.362358</td>\n",
       "      <td>-48.232976</td>\n",
       "      <td>guariba</td>\n",
       "      <td>SP</td>\n",
       "      <td>75265.0</td>\n",
       "      <td>-16.746337</td>\n",
       "      <td>-48.514624</td>\n",
       "      <td>vianopolis</td>\n",
       "      <td>GO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>66922902710d126a0e7d26b0e3805106</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>59296</td>\n",
       "      <td>31842.0</td>\n",
       "      <td>-19.840168</td>\n",
       "      <td>-43.923299</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>59296.0</td>\n",
       "      <td>-5.767733</td>\n",
       "      <td>-35.275467</td>\n",
       "      <td>sao goncalo do amarante</td>\n",
       "      <td>RN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>2c9e548be18521d1c43cde1c582c6de8</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>9195</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>-23.551707</td>\n",
       "      <td>-46.260979</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "      <td>9195.0</td>\n",
       "      <td>-23.675037</td>\n",
       "      <td>-46.524784</td>\n",
       "      <td>santo andre</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp order_delivered_carrier_date  \\\n",
       "0    delivered      2017-10-02 10:56:33          2017-10-04 19:55:00   \n",
       "1    delivered      2018-07-24 20:41:37          2018-07-26 14:31:00   \n",
       "2    delivered      2018-08-08 08:38:49          2018-08-08 13:50:00   \n",
       "3    delivered      2017-11-18 19:28:06          2017-11-22 13:39:59   \n",
       "4    delivered      2018-02-13 21:18:39          2018-02-14 19:46:34   \n",
       "\n",
       "  order_delivered_customer_date order_estimated_delivery_date  \\\n",
       "0           2017-10-10 21:25:13           2017-10-18 00:00:00   \n",
       "1           2018-08-07 15:27:45           2018-08-13 00:00:00   \n",
       "2           2018-08-17 18:06:29           2018-09-04 00:00:00   \n",
       "3           2017-12-02 00:28:42           2017-12-15 00:00:00   \n",
       "4           2018-02-16 18:17:02           2018-02-26 00:00:00   \n",
       "\n",
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3504c0cb71d7fa48d967e0e4c94d59d9                  9350.0   \n",
       "1  289cdb325fb7e7f891c38608bf9e0962                 31570.0   \n",
       "2  4869f7a5dfa277a7dca6462dcf3b52b2                 14840.0   \n",
       "3  66922902710d126a0e7d26b0e3805106                 31842.0   \n",
       "4  2c9e548be18521d1c43cde1c582c6de8                  8752.0   \n",
       "\n",
       "   customer_zip_code_prefix  geolocation_zip_code_prefix_seller  \\\n",
       "0                      3149                              9350.0   \n",
       "1                     47813                             31570.0   \n",
       "2                     75265                             14840.0   \n",
       "3                     59296                             31842.0   \n",
       "4                      9195                              8752.0   \n",
       "\n",
       "   geolocation_lat_seller  geolocation_lng_seller geolocation_city_seller  \\\n",
       "0              -23.680114              -46.452454                    maua   \n",
       "1              -19.810119              -43.984727          belo horizonte   \n",
       "2              -21.362358              -48.232976                 guariba   \n",
       "3              -19.840168              -43.923299          belo horizonte   \n",
       "4              -23.551707              -46.260979         mogi das cruzes   \n",
       "\n",
       "  geolocation_state_seller  geolocation_zip_code_prefix_customer  \\\n",
       "0                       SP                                3149.0   \n",
       "1                       MG                               47813.0   \n",
       "2                       SP                               75265.0   \n",
       "3                       MG                               59296.0   \n",
       "4                       SP                                9195.0   \n",
       "\n",
       "   geolocation_lat_customer  geolocation_lng_customer  \\\n",
       "0                -23.574809                -46.587471   \n",
       "1                -12.169860                -44.988369   \n",
       "2                -16.746337                -48.514624   \n",
       "3                 -5.767733                -35.275467   \n",
       "4                -23.675037                -46.524784   \n",
       "\n",
       "  geolocation_city_customer geolocation_state_customer  \n",
       "0                 sao paulo                         SP  \n",
       "1                 barreiras                         BA  \n",
       "2                vianopolis                         GO  \n",
       "3   sao goncalo do amarante                         RN  \n",
       "4               santo andre                         SP  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-drop rows with missing values\n",
    "filtered_orders = filtered_orders.drop(columns=[\"order_approved_at\"])\n",
    "# This line drops the \"order_approved_at\" column from the filtered_orders DataFrame. This column is not necessary for the analysis being performed.\n",
    "\n",
    "filtered_orders = filtered_orders.dropna()\n",
    "# This line drops any rows in the filtered_orders DataFrame that contain missing values. This is a common data preprocessing step to ensure that the dataset is clean and complete.\n",
    "\n",
    "\n",
    "filtered_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0b4e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function to calculate distance\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Compute distance between two pairs of (lat, lng)\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * 6371 * asin(sqrt(a))\n",
    "\n",
    "# This line defines a function called haversine_distance that takes four arguments: lon1, lat1, lon2, and lat2. These arguments represent the longitude and latitude coordinates of two points on the globe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06557312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_package_size(items, products):\n",
    "    # Get Package Size\n",
    "    df_tmp = items[['order_id', 'product_id']].merge(products[['product_id', 'product_length_cm', 'product_height_cm',\n",
    "                                                               'product_width_cm', 'product_weight_g']],\n",
    "                                                     on=\"product_id\",\n",
    "                                                     how=\"outer\")\n",
    "    df_tmp.loc[:, \"product_size_cm3\"] = \\\n",
    "        df_tmp['product_length_cm']*df_tmp['product_width_cm'] * df_tmp['product_height_cm']\n",
    "    orders_size_weight = df_tmp.groupby(\"order_id\", as_index=False).sum()[['order_id', 'product_size_cm3',\n",
    "                                                                           'product_weight_g']]\n",
    "    return orders_size_weight\n",
    "\n",
    "# The code above defines a function called get_package_size that takes two arguments: items and products, which are Pandas DataFrames containing information about products and the items ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61e0c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_int(dataframe_series):\n",
    "\n",
    "    if dataframe_series.dtype == 'object':\n",
    "        # This line checks if the data type of the input dataframe_series is \"object\", which typically represents string or categorical data.\n",
    "\n",
    "        dataframe_series = LabelEncoder().fit_transform(dataframe_series)\n",
    "        # This line uses the LabelEncoder() method from the scikit-learn library to encode the string or categorical data as integers. This is a common preprocessing step in machine learning to convert non-numeric data into a format that can be used by algorithms. The fit_transform() method fits the encoder to the data and transforms it.\n",
    "        \n",
    "    return dataframe_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77c0de6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe code above applies the describe() method to a Pandas DataFrame called orders, which provides summary statistics of the data in the DataFrame. Here's a brief explanation of what each statistic means:\\n\\ncount: the number of non-missing values in each column\\nmean: the average value of each column\\nstd: the standard deviation of each column\\nmin: the minimum value of each column\\n25%: the first quartile of each column (25th percentile)\\n50%: the second quartile of each column (50th percentile, equivalent to the median)\\n75%: the third quartile of each column (75th percentile)\\nmax: the maximum value of each column\\nThe describe() method is useful for quickly getting an overview of the data in a DataFrame, including identifying potential outliers or unusual patterns in the data.\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It gives the numerical statistical information of the dataframe\n",
    "orders.describe()\n",
    "\n",
    "'''\n",
    "The code above applies the describe() method to a Pandas DataFrame called orders, which provides summary statistics of the data in the DataFrame. Here's a brief explanation of what each statistic means:\n",
    "\n",
    "count: the number of non-missing values in each column\n",
    "mean: the average value of each column\n",
    "std: the standard deviation of each column\n",
    "min: the minimum value of each column\n",
    "25%: the first quartile of each column (25th percentile)\n",
    "50%: the second quartile of each column (50th percentile, equivalent to the median)\n",
    "75%: the third quartile of each column (75th percentile)\n",
    "max: the maximum value of each column\n",
    "The describe() method is useful for quickly getting an overview of the data in a DataFrame, including identifying potential outliers or unusual patterns in the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc08ccdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                                   0\n",
       "customer_id                                0\n",
       "order_status                               0\n",
       "order_purchase_timestamp                   0\n",
       "order_approved_at                        161\n",
       "order_delivered_carrier_date            1968\n",
       "order_delivered_customer_date           3229\n",
       "order_estimated_delivery_date              0\n",
       "seller_id                                775\n",
       "seller_zip_code_prefix                   775\n",
       "customer_zip_code_prefix                   0\n",
       "geolocation_zip_code_prefix_seller      1028\n",
       "geolocation_lat_seller                  1028\n",
       "geolocation_lng_seller                  1028\n",
       "geolocation_city_seller                 1028\n",
       "geolocation_state_seller                1028\n",
       "geolocation_zip_code_prefix_customer     306\n",
       "geolocation_lat_customer                 306\n",
       "geolocation_lng_customer                 306\n",
       "geolocation_city_customer                306\n",
       "geolocation_state_customer               306\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It returns the number of null values in the dataframe for every column feature\n",
    "# Using info() we can view the number of non-null values whereas isnull() gives the number of null values\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b79e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X_train, X_test):\n",
    "    '''\n",
    "    The code above defines a function called scaling that performs feature scaling using the StandardScaler class from scikit-learn.\n",
    "    '''\n",
    "    sc_X = StandardScaler()\n",
    "    X_train_scaled = sc_X.fit_transform(X_train)\n",
    "    X_test_scaled = sc_X.fit_transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58c09681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(final_df, columns_for_train, columns_for_pred, i_flag):\n",
    "    '''\n",
    "    This function is a convenient way to split a DataFrame into training and testing sets for machine learning purposes. The i_flag parameter is used to avoid a warning message related to the NumPy library, and the columns_for_train and columns_for_pred parameters allow for flexible selection of features and target variables.\n",
    "    '''\n",
    "\n",
    "    if i_flag:\n",
    "        from sklearnex import patch_sklearn  # pylint: disable=C0415, E0401\n",
    "        patch_sklearn()\n",
    "    from sklearn.model_selection import train_test_split  # pylint: disable=C0415\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(final_df[columns_for_train], final_df[columns_for_pred],\n",
    "                                                        test_size=0.3, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69e667c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m     filtered_orders\u001b[38;5;241m.\u001b[39mloc[:, column] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(filtered_orders[column])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# These lines convert several time-related columns in the filtered_orders DataFrame from string format to datetime format using the pd.to_datetime function.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m filtered_orders\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (filtered_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_delivered_customer_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m---> 22\u001b[0m                                        filtered_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_purchase_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdays\n\u001b[0;32m     23\u001b[0m filtered_orders\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mest_wait_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (filtered_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_estimated_delivery_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m     24\u001b[0m                                            filtered_orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_purchase_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdays\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# These lines calculate the wait time and estimated wait time for each order in days, based on the difference between the purchase time and the delivered/estimated delivery time.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 643\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "filtered_orders['distance'] = filtered_orders.apply(lambda row: haversine_distance(row[\"geolocation_lng_seller\"],\n",
    "                                                                                   row[\"geolocation_lat_seller\"],\n",
    "                                                                                   row[\"geolocation_lng_customer\"],\n",
    "                                                                                   row[\"geolocation_lat_customer\"],),\n",
    "                                                    axis=1,)\n",
    "# This line creates a new column in the filtered_orders DataFrame called \"distance\" by applying the haversine_distance function to calculate the distance between the seller and the customer for each row in the DataFrame.\n",
    "\n",
    "\n",
    "orders_size_weight = get_package_size(items, products)\n",
    "filtered_orders = filtered_orders.merge(orders_size_weight, on='order_id', how='left')\n",
    "# These lines merge information about the package size and weight for each order from the items and products DataFrames into the filtered_orders DataFrame.\n",
    "\n",
    "\n",
    "# process time columns\n",
    "time_columns = ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "for column in time_columns:\n",
    "    filtered_orders.loc[:, column] = pd.to_datetime(filtered_orders[column])\n",
    "# These lines convert several time-related columns in the filtered_orders DataFrame from string format to datetime format using the pd.to_datetime function.\n",
    "\n",
    "\n",
    "filtered_orders.loc[:, \"wait_time\"] = (filtered_orders['order_delivered_customer_date'] -\n",
    "                                       filtered_orders['order_purchase_timestamp']).dt.days\n",
    "filtered_orders.loc[:, \"est_wait_time\"] = (filtered_orders['order_estimated_delivery_date'] -\n",
    "                                           filtered_orders['order_purchase_timestamp']).dt.days\n",
    "# These lines calculate the wait time and estimated wait time for each order in days, based on the difference between the purchase time and the delivered/estimated delivery time.\n",
    "\n",
    "\n",
    "filtered_orders.loc[:, \"purchase_dow\"] = filtered_orders.order_purchase_timestamp.dt.dayofweek\n",
    "filtered_orders.loc[:, \"year\"] = filtered_orders.order_purchase_timestamp.dt.year\n",
    "filtered_orders.loc[:, \"purchase_month\"] = filtered_orders.order_purchase_timestamp.dt.month\n",
    "# These lines extract the day of the week, year, and month from the order_purchase_timestamp column in the filtered_orders DataFrame.\n",
    "\n",
    "\n",
    "final_df = filtered_orders[['purchase_dow', 'purchase_month', 'year', 'product_size_cm3', 'product_weight_g',\n",
    "                            'geolocation_state_customer', 'geolocation_state_seller', 'distance',\n",
    "                            'wait_time', 'est_wait_time']]\n",
    "# This line creates a new DataFrame called final_df by selecting certain columns from the filtered_orders DataFrame.\n",
    "\n",
    "final_df['delay'] = final_df['wait_time'] - final_df['est_wait_time']\n",
    "final_df['delay'] = final_df['delay'] > 0\n",
    "final_df['delay'] = final_df['delay'].astype(int)\n",
    "# These lines calculate the delay time for each order and encode it as a binary variable indicating whether there was a delay or not.\n",
    "\n",
    "final_df_enc = final_df.apply(lambda x: object_to_int(x))\n",
    "# This line applies the object_to_int function to each column in the final_df DataFrame to convert categorical variables into integer format. The object_to_int function is not shown in the code provided, but it likely uses the LabelEncoder class from the scikit-learn library to perform the conversion.\n",
    "\n",
    "final_df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580b2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "final_df_enc.to_csv('final_OTD_time_forecasting_dataframe.csv', index=False)\n",
    "\n",
    "# Students will be using this exported .csv file in working on a Streamlit based EDA activity in Week 12 - AI Project Deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09658d09-d161-4427-9034-76bdf8286103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_purchase_timestamp         object\n",
      "order_delivered_customer_date    object\n",
      "order_estimated_delivery_date    object\n",
      "dtype: object\n",
      "After conversion:\n",
      "order_purchase_timestamp         datetime64[ns]\n",
      "order_delivered_customer_date    datetime64[ns]\n",
      "order_estimated_delivery_date    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# First, check the data types of these columns\n",
    "print(filtered_orders[time_columns].dtypes)\n",
    "\n",
    "# Try explicit conversion with errors='coerce' to handle problematic values\n",
    "for column in time_columns:\n",
    "    filtered_orders[column] = pd.to_datetime(filtered_orders[column], errors='coerce')\n",
    "\n",
    "# Check again to confirm conversion worked\n",
    "print(\"After conversion:\")\n",
    "print(filtered_orders[time_columns].dtypes)\n",
    "\n",
    "# Now try calculating the time differences\n",
    "# Use timedelta directly rather than .dt accessor\n",
    "filtered_orders[\"wait_time\"] = (filtered_orders['order_delivered_customer_date'] - \n",
    "                               filtered_orders['order_purchase_timestamp']).dt.days\n",
    "\n",
    "filtered_orders[\"est_wait_time\"] = (filtered_orders['order_estimated_delivery_date'] - \n",
    "                                   filtered_orders['order_purchase_timestamp']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9493846-6fcf-43c1-8cdd-4c9be79eb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time columns with errors='coerce' to handle any problematic values\n",
    "for column in time_columns:\n",
    "    filtered_orders[column] = pd.to_datetime(filtered_orders[column], errors='coerce')\n",
    "\n",
    "# Now calculate the time differences after successful conversion\n",
    "filtered_orders[\"wait_time\"] = (filtered_orders['order_delivered_customer_date'] - \n",
    "                               filtered_orders['order_purchase_timestamp']).dt.days\n",
    "\n",
    "filtered_orders[\"est_wait_time\"] = (filtered_orders['order_estimated_delivery_date'] - \n",
    "                                   filtered_orders['order_purchase_timestamp']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "313c3071-30ea-4e6d-ad37-90cd1f447da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jashp\\AppData\\Local\\Temp\\ipykernel_8164\\1925287353.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['delay'] = final_df['wait_time'] - final_df['est_wait_time']\n",
      "C:\\Users\\jashp\\AppData\\Local\\Temp\\ipykernel_8164\\1925287353.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['delay'] = final_df['delay'] > 0  # True if actual wait > estimated wait\n",
      "C:\\Users\\jashp\\AppData\\Local\\Temp\\ipykernel_8164\\1925287353.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['delay'] = final_df['delay'].astype(int)  # Convert boolean to 0/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_dow</th>\n",
       "      <th>purchase_month</th>\n",
       "      <th>year</th>\n",
       "      <th>product_size_cm3</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>geolocation_state_customer</th>\n",
       "      <th>geolocation_state_seller</th>\n",
       "      <th>distance</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>est_wait_time</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>18.063837</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>4693.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>856.292580</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>9576.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>514.130333</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>1822.800366</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>11475.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>30.174037</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_dow  purchase_month  year  product_size_cm3  product_weight_g  \\\n",
       "0             0              10  2017            1976.0             500.0   \n",
       "1             1               7  2018            4693.0             400.0   \n",
       "2             2               8  2018            9576.0             420.0   \n",
       "3             5              11  2017            6000.0             450.0   \n",
       "4             1               2  2018           11475.0             250.0   \n",
       "\n",
       "   geolocation_state_customer  geolocation_state_seller     distance  \\\n",
       "0                          25                        20    18.063837   \n",
       "1                           4                         7   856.292580   \n",
       "2                           8                        20   514.130333   \n",
       "3                          19                         7  1822.800366   \n",
       "4                          25                        20    30.174037   \n",
       "\n",
       "   wait_time  est_wait_time  delay  \n",
       "0          8             15      0  \n",
       "1         13             19      0  \n",
       "2          9             26      0  \n",
       "3         13             26      0  \n",
       "4          2             12      0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract time-related features\n",
    "filtered_orders.loc[:, \"purchase_dow\"] = filtered_orders.order_purchase_timestamp.dt.dayofweek\n",
    "filtered_orders.loc[:, \"year\"] = filtered_orders.order_purchase_timestamp.dt.year\n",
    "filtered_orders.loc[:, \"purchase_month\"] = filtered_orders.order_purchase_timestamp.dt.month\n",
    "\n",
    "# Create the final DataFrame with selected features\n",
    "final_df = filtered_orders[['purchase_dow', 'purchase_month', 'year', 'product_size_cm3', 'product_weight_g',\n",
    "                           'geolocation_state_customer', 'geolocation_state_seller', 'distance',\n",
    "                           'wait_time', 'est_wait_time']]\n",
    "\n",
    "# Calculate and encode delay\n",
    "final_df['delay'] = final_df['wait_time'] - final_df['est_wait_time']\n",
    "final_df['delay'] = final_df['delay'] > 0  # True if actual wait > estimated wait\n",
    "final_df['delay'] = final_df['delay'].astype(int)  # Convert boolean to 0/1\n",
    "\n",
    "# Apply encoding to categorical variables\n",
    "final_df_enc = final_df.apply(lambda x: object_to_int(x))\n",
    "\n",
    "# Now you can view the result\n",
    "final_df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4266f4de-95bb-46cb-83e1-f7d9b483c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "columns_for_regression_train = ['purchase_dow', 'purchase_month', 'year', 'product_size_cm3', 'product_weight_g',\n",
    "                                'geolocation_state_customer', 'geolocation_state_seller',\n",
    "                                'distance']\n",
    "columns_for_regression_pred = ['wait_time']\n",
    "# These two lines define lists of column names to be used as predictors and targets, respectively.\n",
    "\n",
    "X_train_reg_0, X_test_reg_0, y_train_reg_0, y_test_reg_0 = train_test_split(final_df_enc[columns_for_regression_train],\n",
    "                                                                            final_df_enc[columns_for_regression_pred],\n",
    "                                                                            random_state=42)\n",
    "\n",
    "# This line splits the final_df_enc DataFrame into training and testing sets for regression modeling. Specifically, the predictors defined in columns_for_regression_train are assigned to X_train_reg_0 and X_test_reg_0, while the target variable defined in columns_for_regression_pred is assigned to y_train_reg_0 and y_test_reg_0. The train_test_split function is used to randomly split the data into training and testing sets, with 75% of the data assigned to training and 25% assigned to testing. The random_state parameter is set to 42 to ensure reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "995a86ea-06cd-462c-9290-002b9744704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79933"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(dataframe)returns the no of rows in the dataframe\n",
    "len(X_train_reg_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ce4f770-3d2c-4db8-96d3-82e4c26da274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26645"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_reg_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43ae53dc-3620-4686-935d-da2ca9d003bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_dow</th>\n",
       "      <th>purchase_month</th>\n",
       "      <th>year</th>\n",
       "      <th>product_size_cm3</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>geolocation_state_customer</th>\n",
       "      <th>geolocation_state_seller</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>352.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>7.926935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34983</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>3648.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>737.751884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67135</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2142.507233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98003</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>7590.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>60.040963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23127</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>741.317012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase_dow  purchase_month  year  product_size_cm3  product_weight_g  \\\n",
       "27991             5              11  2017             352.0             250.0   \n",
       "34983             3               4  2018            3648.0             150.0   \n",
       "67135             0               8  2018           31500.0            4150.0   \n",
       "98003             3               2  2018            7590.0            1700.0   \n",
       "23127             3              12  2017           25000.0             550.0   \n",
       "\n",
       "       geolocation_state_customer  geolocation_state_seller     distance  \n",
       "27991                          25                        20     7.926935  \n",
       "34983                          22                        13   737.751884  \n",
       "67135                           5                        20  2142.507233  \n",
       "98003                          25                        20    60.040963  \n",
       "23127                          22                        20   741.317012  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the first five entry of the dataframe\n",
    "\n",
    "X_train_reg_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0534bd8-39f4-4286-a4b5-5348fca4bb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_dow</th>\n",
       "      <th>purchase_month</th>\n",
       "      <th>year</th>\n",
       "      <th>product_size_cm3</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>geolocation_state_customer</th>\n",
       "      <th>geolocation_state_seller</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32984</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>649.023624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9502</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>344.663387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36433</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>4913.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>298.122964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46430</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>9072.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>500.617736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36545</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>8.395098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase_dow  purchase_month  year  product_size_cm3  product_weight_g  \\\n",
       "32984             2               6  2018            7600.0             600.0   \n",
       "9502              0               9  2017            1344.0             350.0   \n",
       "36433             6               2  2018            4913.0             350.0   \n",
       "46430             3               3  2018            9072.0             720.0   \n",
       "36545             0               3  2018            3000.0             150.0   \n",
       "\n",
       "       geolocation_state_customer  geolocation_state_seller    distance  \n",
       "32984                          23                        20  649.023624  \n",
       "9502                           18                        20  344.663387  \n",
       "36433                          25                        20  298.122964  \n",
       "46430                          10                        20  500.617736  \n",
       "36545                          18                        14    8.395098  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the first five entry of the dataframe\n",
    "\n",
    "X_test_reg_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "040bb298-dd40-4c53-90b3-4ca46037d57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34983</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67135</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98003</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23127</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wait_time\n",
       "27991          4\n",
       "34983          7\n",
       "67135         16\n",
       "98003          3\n",
       "23127         15"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the first five entry of the dataframe\n",
    "\n",
    "y_train_reg_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e713882-44b9-43fd-9f8a-8f814b2755ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code block defines several utility functions for making predictions with different regression models and evaluating their performance.\n",
    "'''\n",
    "\n",
    "def xgb_predict_reg(xgb_model, x_test_reg, y_test_reg):\n",
    "    '''\n",
    "    This function takes an XGBoost regression model, test input data (x_test_reg), and test output data (y_test_reg) as inputs. It uses the model to make predictions on the test data, calculates the mean squared error (MSE) of the predictions compared to the actual test output data, and returns the MSE and the time it took to make the predictions.\n",
    "    '''\n",
    "    xgb_pred_start = time.time()\n",
    "    y_pred = xgb_model.predict(x_test_reg)\n",
    "    xgb_pred_time = time.time() - xgb_pred_start\n",
    "    xgb_mse = np.square(np.subtract(y_test_reg.values.reshape(-1), y_pred)).mean()\n",
    "    return xgb_mse, xgb_pred_time\n",
    "        \n",
    "def rf_predict_reg(rf_model, x_test_reg, y_test_reg):\n",
    "    '''\n",
    "    This function is similar to the previous one but takes a random forest regression model instead of an XGBoost model.\n",
    "    '''\n",
    "    rf_pred_start = time.time()\n",
    "    y_pred = rf_model.predict(x_test_reg)\n",
    "    rf_pred_time = time.time() - rf_pred_start\n",
    "    rf_mse = np.square(np.subtract(y_test_reg.values.reshape(-1), y_pred)).mean()\n",
    "    return rf_mse, rf_pred_time\n",
    "\n",
    "def SV_predict_reg(svr_model, x_test_reg, y_test_reg):\n",
    "    '''\n",
    "    This function is similar to the previous two but takes a support vector regression (SVR) model instead.\n",
    "    '''\n",
    "    svr_pred_start = time.time()\n",
    "    y_pred = svr_model.predict(x_test_reg)\n",
    "    svr_pred_time = time.time() - svr_pred_start\n",
    "    svr_mse = np.square(np.subtract(y_test_reg.values.reshape(-1), y_pred)).mean()\n",
    "    return svr_mse, svr_pred_time\n",
    "\n",
    "def ensemble_predict_reg(ensemble_model, x_test_reg, y_test_reg):\n",
    "    '''\n",
    "    This function takes an ensemble model (e.g. a voting regressor) instead of a single regression model and performs the same evaluation as the previous functions.\n",
    "    '''\n",
    "    ensemble_pred_start = time.time()\n",
    "    y_pred = ensemble_model.predict(x_test_reg)\n",
    "    ensemble_pred_time = time.time() - ensemble_pred_start\n",
    "    ensemble_mse = np.square(np.subtract(y_test_reg.values.reshape(-1), y_pred)).mean()\n",
    "    return ensemble_mse, ensemble_pred_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35d24fed-d42a-4d5b-ae17-7c6d641e57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_train = pd.DataFrame(X_train_reg_0, columns=columns_for_regression_train)\n",
    "hyper_train['wait_time'] = y_train_reg_0['wait_time'].values\n",
    "# These lines create a new Pandas DataFrame called hyper_train from the training set (X_train_reg_0 and y_train_reg_0) and add a new column called \"wait_time\" to it. The columns_for_regression_train variable specifies which columns from X_train_reg_0 to include in the new DataFrame. The \"wait_time\" column is added to hyper_train by taking the values from the \"wait_time\" column of y_train_reg_0.\n",
    "\n",
    "hyper_train_section = hyper_train.sample(8192, random_state=42)\n",
    "# This line randomly samples a subset of 8192 rows from hyper_train and creates a new DataFrame called hyper_train_section. The random_state=42 parameter ensures that the random sampling is reproducible.\n",
    "\n",
    "X_train_reg = hyper_train_section[columns_for_regression_train]\n",
    "y_train_reg = hyper_train_section[columns_for_regression_pred]\n",
    "# These lines split the hyper_train_section DataFrame into the training set (X_train_reg) and the target variable (y_train_reg) based on the columns_for_regression_train and columns_for_regression_pred variables, respectively. columns_for_regression_train specifies which columns from hyper_train_section to include in X_train_reg, while columns_for_regression_pred specifies which column(s) to use as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5ae91ec-39ab-43e9-9aeb-a39d9d8a1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for xgb and random forests and SV for hyper parameter tuning\n",
    "xgb_params = {'n_estimators': [500, 1000], 'max_depth': [10, 20], 'tree_method': ['hist']}\n",
    "# This dictionary contains hyperparameters for the XGBoost model, including the number of estimators (500 or 1000), the maximum depth of each tree (10 or 20), and the tree construction method ('hist').\n",
    "\n",
    "rf_params = {'n_estimators': [500, 1000], 'max_depth': [10, 20]}\n",
    "# This dictionary contains hyperparameters for the Random Forest model, including the number of estimators (500 or 1000) and the maximum depth of each tree (10 or 20).\n",
    "\n",
    "SV_params = {'C': [10, 20], 'epsilon': [0.1, 0.05], 'kernel': ['rbf'], 'gamma': ['auto']}\n",
    "# This dictionary contains hyperparameters for the Support Vector Regression model, including the penalty parameter C (10 or 20), the epsilon parameter (0.1 or 0.05), the kernel function ('rbf'), and the kernel coefficient ('auto').\n",
    "\n",
    "ensemble_params = {'weights': [(1, 1, 1), (1, 2, 1), (2, 1, 1), (1, 1, 2)]}\n",
    "# This dictionary contains hyperparameters for the VotingRegressor model, including the weights assigned to each model in the ensemble. The weights are represented as tuples, with each element representing the weight of a different model. For example, the tuple (1, 2, 1) represents an ensemble where the second model has twice the weight of the first and third models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "443d9451-8388-41fc-880e-7c9cd620ab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Tuning for XGB\n"
     ]
    }
   ],
   "source": [
    "print('Running Hyperparameter Tuning for XGB')\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "# This line creates a new instance of the XGBRegressor class from the XGBoost library. This will be the base model that will be tuned using GridSearchCV.\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=4, n_jobs=-1, verbose=True)\n",
    "\n",
    "# This line creates a new instance of the GridSearchCV class from the scikit-learn library. The GridSearchCV class performs an exhaustive search over a specified parameter grid to find the combination of hyperparameters that yields the best performance. In this case, the GridSearchCV object is created with the following arguments:\n",
    "\n",
    "# xgb_model: The XGBoost model instance that will be tuned.\n",
    "# xgb_params: A dictionary of hyperparameters and their possible values.\n",
    "# cv=4: The number of cross-validation folds to use in the search. In this case, 4-fold cross-validation will be used.\n",
    "# n_jobs=-1: The number of CPU cores to use in parallel for training the models. In this case, -1 is specified to use all available CPU cores.\n",
    "# verbose=True: Whether to print progress messages during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a20847fe-9b4e-43b8-8134-e5db5767b222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    }
   ],
   "source": [
    "# record time\n",
    "xgb_start = time.time()\n",
    "# This line records the current time using the time.time() function and saves it to the variable xgb_start. This is used to calculate the time it takes to train the XGBoost model.\n",
    "\n",
    "xgb_grid.fit(X_train_reg, y_train_reg)\n",
    "# This line fits a grid search on the XGBoost model with the training data X_train_reg and y_train_reg. The grid search involves searching through a range of hyperparameters to find the best combination of hyperparameters for the XGBoost model.\n",
    "\n",
    "xgb_hyper_time = time.time()-xgb_start\n",
    "# This line calculates the time it took to train the XGBoost model by subtracting xgb_start from the current time using the time.time() function. The result is saved to the variable xgb_hyper_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0092123e-9d94-4bff-b3bc-836a1b36abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best grid\n",
    "xgb_best_grid = xgb_grid.best_estimator_\n",
    "# This line takes the best estimator found by the GridSearchCV object xgb_grid and assigns it to the variable xgb_best_grid. The best_estimator_ attribute of the GridSearchCV object is the model that performed the best according to the chosen evaluation metric and hyperparameter search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "468b2b27-df09-4f61-b337-f0d7ba37cdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning time for for: XGB:  23.646058082580566\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Hyperparameter tuning time for for: XGB: ', str(xgb_hyper_time))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30b5b768-f050-4372-923e-25eeb2b999a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Tuning for RF\n"
     ]
    }
   ],
   "source": [
    "print('Running Hyperparameter Tuning for RF')\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=4, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72488946-9f9e-416c-9fde-79abdfa05160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    }
   ],
   "source": [
    "# record time\n",
    "rf_start = time.time()\n",
    "rf_grid.fit(X_train_reg, y_train_reg.values.ravel())\n",
    "rf_hyper_time = time.time()-rf_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f1d0981a-b4c7-4637-bc79-709e92bbb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best grid\n",
    "rf_best_grid = rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3f10b0c4-7966-44b0-a840-132e8980fa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning time for for: RF:  137.19414687156677\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Hyperparameter tuning time for for: RF: ', str(rf_hyper_time))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "21106740-563a-4ec7-9395-75ca93c0f13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Tuning for SV\n"
     ]
    }
   ],
   "source": [
    "print('Running Hyperparameter Tuning for SV')\n",
    "SV_model = SVR()\n",
    "SV_grid = GridSearchCV(SV_model, SV_params, cv=4, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d43c7b3f-31c0-4c7d-a563-a35727e627f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    }
   ],
   "source": [
    "# record time\n",
    "SV_start = time.time()\n",
    "SV_grid.fit(X_train_reg, y_train_reg.values.ravel())\n",
    "SV_hyper_time = time.time()-SV_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f78b35f0-9610-4479-a3c9-b63c0d1539ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best grid and params\n",
    "SV_best_grid = SV_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d6eaa08-1dab-433a-b6a6-954c98ffc790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning time for for: SV:  63.603028297424316\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Hyperparameter tuning time for for: SV: ', str(SV_hyper_time))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d7ad037-6518-4826-a2f8-2cf1cc31f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter Tuning for ensemble\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning for ensemble model using the \"Best Grid for SGB, RF, SV\"\n",
    "\n",
    "print('Running Hyperparameter Tuning for ensemble')\n",
    "voting_model = VotingRegressor(estimators=[('xgb', xgb_best_grid), ('rf', rf_best_grid), ('SV', SV_best_grid)])\n",
    "# This line defines a voting regressor model (voting_model) that combines three base models: XGBoost (xgb_best_grid), Random Forest (rf_best_grid), and Support Vector Regression (SV_best_grid). The estimators parameter takes a list of tuples, where each tuple contains the name of the model and the model object.\n",
    "\n",
    "ensemble_grid = GridSearchCV(voting_model, ensemble_params, cv=4, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6fec4fef-5ea4-47bd-97f8-b6dad6ff1d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    }
   ],
   "source": [
    "# record time\n",
    "ensemble_start = time.time()\n",
    "ensemble_grid.fit(X_train_reg, y_train_reg.values.ravel())\n",
    "ensemble_hyper_time = time.time()-ensemble_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ba2eeacf-6a83-408e-942f-af57d031aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best params\n",
    "ensemble_best_params = ensemble_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a16d767c-e919-4823-9b22-ff73c4e3f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning time for for: ensemble model:  265.25255370140076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Hyperparameter tuning time for for: ensemble model: ', str(ensemble_hyper_time))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc8df362-c4c2-40e1-95fc-8c8ed647c619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Training for ensemble model with data length  8192\n",
      "Training time for for: ensemble model:  44.6894268989563\n",
      "\n",
      "\n",
      "Running Training for ensemble model with data length  32768\n",
      "Training time for for: ensemble model:  693.9839329719543\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ti_train = pd.DataFrame(X_train_reg_0, columns=columns_for_regression_train)\n",
    "ti_train['wait_time'] = y_train_reg_0['wait_time'].values\n",
    "# These lines create a new Pandas DataFrame called ti_train by combining the training data (X_train_reg_0) and the corresponding target variable (y_train_reg_0['wait_time']).\n",
    "\n",
    "for data_size in [8192, 32768]:\n",
    "# This line sets up a loop to train the ensemble model on two different data sizes.\n",
    "\n",
    "    ti_train_section = ti_train.sample(data_size, random_state=42)\n",
    "    # This line randomly samples data_size rows from the ti_train DataFrame and creates a new DataFrame called ti_train_section.\n",
    "\n",
    "    X_train_reg = ti_train_section[columns_for_regression_train]\n",
    "    y_train_reg = ti_train_section[columns_for_regression_pred]\n",
    "    # These lines create the feature matrix X_train_reg and the target vector y_train_reg for the current ti_train_section DataFrame.\n",
    "\n",
    "    print('Running Training for ensemble model with data length ', str(data_size))\n",
    "\n",
    "    voting_model = VotingRegressor(estimators=[('xgb', xgb_best_grid), ('rf', rf_best_grid), ('SV', SV_best_grid)],\n",
    "                                   n_jobs=-1, weights=ensemble_best_params['weights'])\n",
    "    # This line creates a new ensemble model using the VotingRegressor class from scikit-learn, and specifying the three models to be used as inputs.\n",
    "\n",
    "    ensemble_model_train_start = time.time()\n",
    "    # This line calculates the training time for the ensemble model on the current ti_train_section.\n",
    "\n",
    "    voting_model.fit(X_train_reg, y_train_reg.values.ravel())\n",
    "    # This line fits the ensemble model to the current ti_train_section DataFrame. \n",
    "\n",
    "    ensemble_model_train_time = time.time() - ensemble_model_train_start\n",
    "    # This line calculates the training time for the ensemble model on the current ti_train_section.\n",
    "\n",
    "    print('Training time for for: ensemble model: ', str(ensemble_model_train_time))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "69c95466-dee7-4c25-9cc6-830805676453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['purchase_dow', 'purchase_month', 'year', 'product_size_cm3', 'product_weight_g', 'geolocation_state_customer', 'geolocation_state_seller', 'distance', 'wait_time']\n",
      "[2.0, 4.0, 2018.0, 4500.0, 1550.0, 18.0, 20.0, 590.8619422803324, 26.0]\n"
     ]
    }
   ],
   "source": [
    "ti_test_base = pd.DataFrame(X_test_reg_0, columns=columns_for_regression_train)\n",
    "ti_test_base['wait_time'] = y_test_reg_0['wait_time'].values\n",
    "# These lines create a Pandas DataFrame ti_test_base from the test features X_test_reg_0 and labels y_test_reg_0 for a regression problem. The column names are specified by columns_for_regression_train. The label column \"wait_time\" is added to the DataFrame.\n",
    "\n",
    "ti_test = pd.concat([ti_test_base, ti_test_base, ti_test_base, ti_test_base])\n",
    "# This line concatenates the ti_test_base DataFrame with itself four times to create a larger test dataset ti_test with four times as many rows as the original ti_test_base. This is a common technique for increasing the size of a small test dataset to improve the reliability of model performance estimates.\n",
    "\n",
    "print(list(ti_test.iloc[1:]))\n",
    "# This line prints a list of the values in the ti_test DataFrame starting from the second row. This is useful for inspecting the content of the DataFrame.\n",
    "\n",
    "print(list(ti_test.iloc[9]))\n",
    "# This line prints a list of the values in the 10th row of the ti_test DataFrame. This is useful for inspecting the content of a specific row in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9bc1f52b-3ce9-487b-9929-b6385485db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Streaming Inference Time for Voting Regressor model:  0.11052105641365051\n"
     ]
    }
   ],
   "source": [
    "modelfile = \"voting_model.pkl\"\n",
    "pickle.dump(voting_model, open(modelfile, 'wb'))  # nosec\n",
    "# These lines save the trained voting_model to a file called \"voting_model.pkl\" using the pickle module.\n",
    "\n",
    "voting_model = pickle.load(open(modelfile, 'rb'))  # nosec\n",
    "# This line loads the trained voting_model from the \"voting_model.pkl\" file.\n",
    "\n",
    "ti_test_section = ti_test.sample(1000, random_state=42)\n",
    "# This line creates a smaller sample dataset of ti_test called ti_test_section by randomly selecting 1000 rows from the original dataset using a random seed of 42.\n",
    "\n",
    "lst_of_stream_times = []\n",
    "for _counter in range(1000):\n",
    "    sample_df = ti_test_section.sample(n=1)\n",
    "    X_test_reg = sample_df[columns_for_regression_train]\n",
    "    y_test_reg = sample_df[columns_for_regression_pred]\n",
    "    ensemble_mse, ensemble_pred_time = ensemble_predict_reg(voting_model, X_test_reg, y_test_reg)  # pylint: disable=W0612\n",
    "    lst_of_stream_times.append(ensemble_pred_time)\n",
    "    # These lines loop through the ti_test_section dataset 1000 times, randomly selecting one row each time and using it to evaluate the voting regressor model's inference time. The results are stored in a list called lst_of_stream_times.\n",
    "\n",
    "avg_stream_time = sum(lst_of_stream_times)/len(lst_of_stream_times)\n",
    "print(\"Average Streaming Inference Time for Voting Regressor model: \", str(avg_stream_time))\n",
    "# This line calculates the average inference time for the voting regressor model over the 1000 iterations and prints the result to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "25fde0e5-f84d-4e62-9021-046375f3fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Inference with data length  10000\n",
      "Inference time and MSE for for XGB:  0.0921320915222168 70.00453035617451\n",
      "Inference time and MSE for for RF:  1.6925809383392334 62.58146619415555\n",
      "Inference time and MSE for for SV:  13.4276282787323 87.77734876567744\n",
      "Inference time and MSE for for Voting model:  53.69127035140991 59.72345478713887\n",
      "\n",
      "\n",
      "Running Inference with data length  30000\n",
      "Inference time and MSE for for XGB:  0.2614753246307373 70.9837933681111\n",
      "Inference time and MSE for for RF:  5.738161087036133 61.91890238529625\n",
      "Inference time and MSE for for SV:  39.84702515602112 85.88216885268929\n",
      "Inference time and MSE for for Voting model:  160.3066725730896 57.81861569955095\n",
      "\n",
      "\n",
      "Running Inference with data length  50000\n",
      "Inference time and MSE for for XGB:  0.41391682624816895 70.66400511128406\n",
      "Inference time and MSE for for RF:  8.684036493301392 61.352628723401345\n",
      "Inference time and MSE for for SV:  66.35199069976807 85.64032956801981\n",
      "Inference time and MSE for for Voting model:  268.1601560115814 57.100934686101546\n",
      "\n",
      "\n",
      "Running Inference with data length  70000\n",
      "Inference time and MSE for for XGB:  0.7191014289855957 71.24619914450291\n",
      "Inference time and MSE for for RF:  12.145233154296875 61.88392130261279\n",
      "Inference time and MSE for for SV:  93.65354681015015 86.34629840534598\n",
      "Inference time and MSE for for Voting model:  314.02466225624084 57.801499997369014\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data_size in [10000, 30000, 50000, 70000]:\n",
    "# This line sets up a loop that iterates over a list of data sizes.\n",
    "\n",
    "    ti_test_section = ti_test.sample(data_size, random_state=42)\n",
    "    # This line creates a random subset of the test data, with the number of rows specified by data_size.\n",
    "\n",
    "    X_test_reg = ti_test_section[columns_for_regression_train]\n",
    "    y_test_reg = ti_test_section[columns_for_regression_pred]\n",
    "    # These lines define the input features (X_test_reg) and output target (y_test_reg) for the regression models. The feature and target columns are specified by columns_for_regression_train and columns_for_regression_pred, respectively.\n",
    "\n",
    "    # Perform prediction - refer to ensemble train function in utils\n",
    "    xgb_mse, xgb_pred_time = xgb_predict_reg(xgb_best_grid, X_test_reg, y_test_reg)\n",
    "    rf_mse, rf_pred_time = rf_predict_reg(rf_best_grid, X_test_reg, y_test_reg)\n",
    "    SV_mse, SV_pred_time = SV_predict_reg(SV_best_grid, X_test_reg, y_test_reg)\n",
    "    ensemble_mse, ensemble_pred_time = ensemble_predict_reg(voting_model, X_test_reg, y_test_reg)\n",
    "    # These lines perform predictions using four machine learning models (xgb_best_grid, rf_best_grid, SV_best_grid, and voting_model) on the subset of test data (X_test_reg and y_test_reg). The functions xgb_predict_reg, rf_predict_reg, SV_predict_reg, and ensemble_predict_reg are used to make the predictions and return the mean squared error (*_mse) and prediction time (*_pred_time) for each model.\n",
    "\n",
    "    print('Running Inference with data length ', str(data_size))\n",
    "    print(\"Inference time and MSE for for XGB: \", ' '.join(map(str, list((xgb_pred_time, xgb_mse)))))\n",
    "    print(\"Inference time and MSE for for RF: \", ' '.join(map(str, list((rf_pred_time, rf_mse)))))\n",
    "    print(\"Inference time and MSE for for SV: \", ' '.join(map(str, list((SV_pred_time, SV_mse)))))\n",
    "    print(\"Inference time and MSE for for Voting model: \", ' '.join(map(str, list((ensemble_pred_time, ensemble_mse)))))\n",
    "    print('\\n')\n",
    "    # These lines print out the results of the predictions for each model, including the data size, inference time, and mean squared error. The results are printed in a formatted way using print statements and join and list functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
